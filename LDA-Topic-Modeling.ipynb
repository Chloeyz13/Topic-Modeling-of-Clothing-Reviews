{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chloeyz13/Topic-Modeling-of-Clothing-Reviews/blob/main/LDA-Topic-Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up Pyspark"
      ],
      "metadata": {
        "id": "vR719diqg6CW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEJuoX-rgaWB"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -qN https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz"
      ],
      "metadata": {
        "id": "K4P8DxMZhAn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"spark-3.2.1-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "CynyifjVhCvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "1S6ouJFxhErC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install nltk, download nltk stopwords"
      ],
      "metadata": {
        "id": "HEOdfEs5hJ5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run in python console\n",
        "import nltk; nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDzdj-X_hPk5",
        "outputId": "ba320c72-072c-4be0-9109-87e51b686bc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK Stop words\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "# Additional words we would like to ignore, for example, for a corpus of emails\n",
        "# stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
        "print(len(stop_words), stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLU-P9iqhaoh",
        "outputId": "b071d50a-d9b4-4f2b-90f6-80a0da7024b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179 ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming and lemmatization"
      ],
      "metadata": {
        "id": "RQf6y59NhkNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# installing other dependencies\n",
        "import pandas as pd\n",
        "# pd.set_option('display.max_rows', None)\n",
        "# pd.set_option('display.max_colwidth', None)\n",
        "import numpy as np\n",
        "\n",
        "import re\n",
        "import string\n",
        "import pprint\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "f2nezxmdhdrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import women's e-commerce clothing reviews"
      ],
      "metadata": {
        "id": "bvPy-crgh50o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nltk.download('inaugural')\n",
        "# nltk.download('punkt')\n",
        "\n",
        "# from nltk.corpus import inaugural"
      ],
      "metadata": {
        "id": "v7FREl7niBjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# speechesDict = {fileid: inaugural.sents(fileid) for fileid in nltk.corpus.inaugural.fileids()}\n",
        "# pp = pprint.PrettyPrinter(indent=2)\n",
        "# pp.pprint(speechesDict)"
      ],
      "metadata": {
        "id": "dJpvqJkQiHY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "url = 'https://raw.githubusercontent.com/singhj/big-data-repo/main/text-proc/reviews.csv'\n",
        "df = pd.read_csv(url)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "aJuc0fxai3cg",
        "outputId": "312e01ae-e5dc-425d-e844-52ec7ed64645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   recNo  Clothing ID  Age                    Title  \\\n",
              "0      0          767   33                      NaN   \n",
              "1      1         1080   34                      NaN   \n",
              "2      2         1077   60  Some major design flaws   \n",
              "3      3         1049   50         My favorite buy!   \n",
              "4      4          847   47         Flattering shirt   \n",
              "\n",
              "                                         Review Text  Rating  Recommended IND  \\\n",
              "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
              "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
              "2  I had such high hopes for this dress and reall...       3                0   \n",
              "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
              "4  This shirt is very flattering to all due to th...       5                1   \n",
              "\n",
              "   Positive Feedback Count   Division Name Department Name Class Name  \n",
              "0                        0       Initmates        Intimate  Intimates  \n",
              "1                        4         General         Dresses    Dresses  \n",
              "2                        0         General         Dresses    Dresses  \n",
              "3                        0  General Petite         Bottoms      Pants  \n",
              "4                        6         General            Tops    Blouses  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3700e6c6-13d2-4120-b479-e490751f991d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>recNo</th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>767</td>\n",
              "      <td>33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Initmates</td>\n",
              "      <td>Intimate</td>\n",
              "      <td>Intimates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1080</td>\n",
              "      <td>34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1077</td>\n",
              "      <td>60</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1049</td>\n",
              "      <td>50</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Pants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>847</td>\n",
              "      <td>47</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3700e6c6-13d2-4120-b479-e490751f991d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3700e6c6-13d2-4120-b479-e490751f991d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3700e6c6-13d2-4120-b479-e490751f991d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPsJwJVFj4NU",
        "outputId": "5effb971-7307-4483-cd21-84df9947351b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23486, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# paragraph = df.loc[0]['Review Text']\n",
        "# paragraph"
      ],
      "metadata": {
        "id": "kBOCLetAj-AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import nltk\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('averaged_perceptron_tagger')\n",
        "# from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "# sent_text = nltk.sent_tokenize(paragraph)\n",
        "# sent_text"
      ],
      "metadata": {
        "id": "rc7yH9H6kroX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all_tagged = [nltk.word_tokenize(sent) for sent in sent_text]\n",
        "# all_tagged"
      ],
      "metadata": {
        "id": "tTNp8i8QlcWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEOPW957mCjv",
        "outputId": "7dbfaf7c-d70d-44b1-d57b-1645e74acff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_dic = {}\n",
        "for i in df.index:\n",
        "  paragraph = str(df.loc[i]['Review Text'])\n",
        "  sent_text = nltk.sent_tokenize(paragraph)\n",
        "  all_tagged = [nltk.word_tokenize(sent) for sent in sent_text]\n",
        "  review_dic[i] = all_tagged"
      ],
      "metadata": {
        "id": "Wk_D_KSgnt7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pp = pprint.PrettyPrinter(indent=2)\n",
        "# pp.pprint(review_dic)"
      ],
      "metadata": {
        "id": "YbxH9wWDoIHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a = [\"who\",\"are\", \"you\"]\n",
        "# a.extend(\"?\")\n",
        "# a"
      ],
      "metadata": {
        "id": "HyWtPL1GrH2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = df.loc[10]['Review Text']\n",
        "paragraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "quU3UqgzriBK",
        "outputId": "6fa1b117-8838-4025-929d-65cb5d86ffc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dress runs small esp where the zipper area runs. i ordered the sp which typically fits me and it was very tight! the material on the top looks and feels very cheap that even just pulling on it will cause it to rip the fabric. pretty disappointed as it was going to be my christmas dress this year! needless to say it will be going back.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def sent_to_words(sentences):\n",
        "#     for sentence in sentences:\n",
        "#         yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "# def collect (sentences):\n",
        "#     speech = []\n",
        "#     for sent in sentences:\n",
        "#         for fragment in sent:\n",
        "#             speech.extend(fragment)\n",
        "#     return speech"
      ],
      "metadata": {
        "id": "Stt0OBFZrjyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#my function\n",
        "def text_to_words(paragraph):\n",
        "  sent_text = nltk.sent_tokenize(str(paragraph))\n",
        "  all_tagged = [nltk.word_tokenize(sent) for sent in sent_text]\n",
        "  flat_list = [item for sublist in all_tagged for item in sublist]\n",
        "  return flat_list"
      ],
      "metadata": {
        "id": "hnp_Ahgltul2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_words(paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qvoQPCSuGEe",
        "outputId": "a7eb7ac8-924b-4a72-f4ef-5818c82c779e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dress',\n",
              " 'runs',\n",
              " 'small',\n",
              " 'esp',\n",
              " 'where',\n",
              " 'the',\n",
              " 'zipper',\n",
              " 'area',\n",
              " 'runs',\n",
              " '.',\n",
              " 'i',\n",
              " 'ordered',\n",
              " 'the',\n",
              " 'sp',\n",
              " 'which',\n",
              " 'typically',\n",
              " 'fits',\n",
              " 'me',\n",
              " 'and',\n",
              " 'it',\n",
              " 'was',\n",
              " 'very',\n",
              " 'tight',\n",
              " '!',\n",
              " 'the',\n",
              " 'material',\n",
              " 'on',\n",
              " 'the',\n",
              " 'top',\n",
              " 'looks',\n",
              " 'and',\n",
              " 'feels',\n",
              " 'very',\n",
              " 'cheap',\n",
              " 'that',\n",
              " 'even',\n",
              " 'just',\n",
              " 'pulling',\n",
              " 'on',\n",
              " 'it',\n",
              " 'will',\n",
              " 'cause',\n",
              " 'it',\n",
              " 'to',\n",
              " 'rip',\n",
              " 'the',\n",
              " 'fabric',\n",
              " '.',\n",
              " 'pretty',\n",
              " 'disappointed',\n",
              " 'as',\n",
              " 'it',\n",
              " 'was',\n",
              " 'going',\n",
              " 'to',\n",
              " 'be',\n",
              " 'my',\n",
              " 'christmas',\n",
              " 'dress',\n",
              " 'this',\n",
              " 'year',\n",
              " '!',\n",
              " 'needless',\n",
              " 'to',\n",
              " 'say',\n",
              " 'it',\n",
              " 'will',\n",
              " 'be',\n",
              " 'going',\n",
              " 'back',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['content'] = df.apply(lambda row: text_to_words(row['Review Text']), axis=1)\n",
        "df['contentLen'] = df.apply(lambda row: len(text_to_words(row['Review Text'])), axis=1)\n",
        "df[['recNo', 'content', 'contentLen']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "R_6gmoJbrrCN",
        "outputId": "ab7ea9ab-13a0-4c41-f43d-489ae7af900e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       recNo                                            content  contentLen\n",
              "0          0  [Absolutely, wonderful, -, silky, and, sexy, a...           8\n",
              "1          1  [Love, this, dress, !, it, 's, sooo, pretty, ....          75\n",
              "2          2  [I, had, such, high, hopes, for, this, dress, ...         110\n",
              "3          3  [I, love, ,, love, ,, love, this, jumpsuit, .,...          31\n",
              "4          4  [This, shirt, is, very, flattering, to, all, d...          41\n",
              "...      ...                                                ...         ...\n",
              "23481  23481  [I, was, very, happy, to, snag, this, dress, a...          31\n",
              "23482  23482  [It, reminds, me, of, maternity, clothes, ., s...          48\n",
              "23483  23483  [This, fit, well, ,, but, the, top, was, very,...          50\n",
              "23484  23484  [I, bought, this, dress, for, a, wedding, i, h...          97\n",
              "23485  23485  [This, dress, in, a, lovely, platinum, is, fem...          23\n",
              "\n",
              "[23486 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cad1fb0b-fb49-416d-bcf0-218d09c4b8a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>recNo</th>\n",
              "      <th>content</th>\n",
              "      <th>contentLen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[Absolutely, wonderful, -, silky, and, sexy, a...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[Love, this, dress, !, it, 's, sooo, pretty, ....</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[I, had, such, high, hopes, for, this, dress, ...</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[I, love, ,, love, ,, love, this, jumpsuit, .,...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[This, shirt, is, very, flattering, to, all, d...</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23481</th>\n",
              "      <td>23481</td>\n",
              "      <td>[I, was, very, happy, to, snag, this, dress, a...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23482</th>\n",
              "      <td>23482</td>\n",
              "      <td>[It, reminds, me, of, maternity, clothes, ., s...</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23483</th>\n",
              "      <td>23483</td>\n",
              "      <td>[This, fit, well, ,, but, the, top, was, very,...</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23484</th>\n",
              "      <td>23484</td>\n",
              "      <td>[I, bought, this, dress, for, a, wedding, i, h...</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23485</th>\n",
              "      <td>23485</td>\n",
              "      <td>[This, dress, in, a, lovely, platinum, is, fem...</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23486 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cad1fb0b-fb49-416d-bcf0-218d09c4b8a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cad1fb0b-fb49-416d-bcf0-218d09c4b8a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cad1fb0b-fb49-416d-bcf0-218d09c4b8a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# combine 'content' into one list\n",
        "data = []\n",
        "for i in range(23486):\n",
        "  data.extend(df.loc[i]['content'])"
      ],
      "metadata": {
        "id": "CqJMe3eWNv_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data) == df['contentLen'].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdX2HGy2OXbb",
        "outputId": "b0ea5b6e-0c5f-4d27-a601-9b4c0f484c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Gensim and spaCy model"
      ],
      "metadata": {
        "id": "KhJZPseWoWTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "!python3 -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5VBu_X0oRDP",
        "outputId": "940ee743-4ef6-4e27-a715-d3cb629052d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.9/dist-packages (4.3.1)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (6.3.0)\n",
            "2023-04-22 01:22:34.704899: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-22 01:22:36.157061: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-sm==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gensim\n",
        "\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# spacy for lemmatization\n",
        "import spacy\n",
        "spacy.load('en_core_web_sm')\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "KoTsPBXeolKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean data"
      ],
      "metadata": {
        "id": "lM3YoxD_NUav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#remove emails\n",
        "data = [re.sub('\\S*@\\S*\\s?', '', word) for word in data]\n",
        "\n",
        "# Remove new line characters\n",
        "data = [re.sub('\\s+', ' ', word) for word in data]\n",
        "\n",
        "# Remove distracting single quotes\n",
        "data = [re.sub(\"\\'\",\" \", word) for word in data]\n",
        "\n",
        "#remove puctuations from data\n",
        "data = [word for word in data if word not in string.punctuation]\n",
        "\n",
        "#remove empty strings\n",
        "data = list(filter(lambda x: x.strip(), data))\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpUQaTvHpPIN",
        "outputId": "1ca5a64a-bd65-4bad-c66e-a7f65fa14c7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Absolutely',\n",
              " 'wonderful',\n",
              " 'silky',\n",
              " 'and',\n",
              " 'sexy',\n",
              " 'and',\n",
              " 'comfortable',\n",
              " 'Love',\n",
              " 'this',\n",
              " 'dress',\n",
              " 'it',\n",
              " ' s',\n",
              " 'sooo',\n",
              " 'pretty',\n",
              " 'i',\n",
              " 'happened',\n",
              " 'to',\n",
              " 'find',\n",
              " 'it',\n",
              " 'in',\n",
              " 'a',\n",
              " 'store',\n",
              " 'and',\n",
              " 'i',\n",
              " ' m',\n",
              " 'glad',\n",
              " 'i',\n",
              " 'did',\n",
              " 'bc',\n",
              " 'i',\n",
              " 'never',\n",
              " 'would',\n",
              " 'have',\n",
              " 'ordered',\n",
              " 'it',\n",
              " 'online',\n",
              " 'bc',\n",
              " 'it',\n",
              " ' s',\n",
              " 'petite',\n",
              " 'i',\n",
              " 'bought',\n",
              " 'a',\n",
              " 'petite',\n",
              " 'and',\n",
              " 'am',\n",
              " '5',\n",
              " '8',\n",
              " 'i',\n",
              " 'love',\n",
              " 'the',\n",
              " 'length',\n",
              " 'on',\n",
              " 'me-',\n",
              " 'hits',\n",
              " 'just',\n",
              " 'a',\n",
              " 'little',\n",
              " 'below',\n",
              " 'the',\n",
              " 'knee',\n",
              " 'would',\n",
              " 'definitely',\n",
              " 'be',\n",
              " 'a',\n",
              " 'true',\n",
              " 'midi',\n",
              " 'on',\n",
              " 'someone',\n",
              " 'who',\n",
              " 'is',\n",
              " 'truly',\n",
              " 'petite',\n",
              " 'I',\n",
              " 'had',\n",
              " 'such',\n",
              " 'high',\n",
              " 'hopes',\n",
              " 'for',\n",
              " 'this',\n",
              " 'dress',\n",
              " 'and',\n",
              " 'really',\n",
              " 'wanted',\n",
              " 'it',\n",
              " 'to',\n",
              " 'work',\n",
              " 'for',\n",
              " 'me',\n",
              " 'i',\n",
              " 'initially',\n",
              " 'ordered',\n",
              " 'the',\n",
              " 'petite',\n",
              " 'small',\n",
              " 'my',\n",
              " 'usual',\n",
              " 'size',\n",
              " 'but',\n",
              " 'i',\n",
              " 'found',\n",
              " 'this',\n",
              " 'to',\n",
              " 'be',\n",
              " 'outrageously',\n",
              " 'small',\n",
              " 'so',\n",
              " 'small',\n",
              " 'in',\n",
              " 'fact',\n",
              " 'that',\n",
              " 'i',\n",
              " 'could',\n",
              " 'not',\n",
              " 'zip',\n",
              " 'it',\n",
              " 'up',\n",
              " 'i',\n",
              " 'reordered',\n",
              " 'it',\n",
              " 'in',\n",
              " 'petite',\n",
              " 'medium',\n",
              " 'which',\n",
              " 'was',\n",
              " 'just',\n",
              " 'ok.',\n",
              " 'overall',\n",
              " 'the',\n",
              " 'top',\n",
              " 'half',\n",
              " 'was',\n",
              " 'comfortable',\n",
              " 'and',\n",
              " 'fit',\n",
              " 'nicely',\n",
              " 'but',\n",
              " 'the',\n",
              " 'bottom',\n",
              " 'half',\n",
              " 'had',\n",
              " 'a',\n",
              " 'very',\n",
              " 'tight',\n",
              " 'under',\n",
              " 'layer',\n",
              " 'and',\n",
              " 'several',\n",
              " 'somewhat',\n",
              " 'cheap',\n",
              " 'net',\n",
              " 'over',\n",
              " 'layers',\n",
              " 'imo',\n",
              " 'a',\n",
              " 'major',\n",
              " 'design',\n",
              " 'flaw',\n",
              " 'was',\n",
              " 'the',\n",
              " 'net',\n",
              " 'over',\n",
              " 'layer',\n",
              " 'sewn',\n",
              " 'directly',\n",
              " 'into',\n",
              " 'the',\n",
              " 'zipper',\n",
              " 'it',\n",
              " 'c',\n",
              " 'I',\n",
              " 'love',\n",
              " 'love',\n",
              " 'love',\n",
              " 'this',\n",
              " 'jumpsuit',\n",
              " 'it',\n",
              " ' s',\n",
              " 'fun',\n",
              " 'flirty',\n",
              " 'and',\n",
              " 'fabulous',\n",
              " 'every',\n",
              " 'time',\n",
              " 'i',\n",
              " 'wear',\n",
              " 'it',\n",
              " 'i',\n",
              " 'get',\n",
              " 'nothing',\n",
              " 'but',\n",
              " 'great',\n",
              " 'compliments',\n",
              " 'This',\n",
              " 'shirt',\n",
              " 'is',\n",
              " 'very',\n",
              " 'flattering',\n",
              " 'to',\n",
              " 'all',\n",
              " 'due',\n",
              " 'to',\n",
              " 'the',\n",
              " 'adjustable',\n",
              " 'front',\n",
              " 'tie',\n",
              " 'it',\n",
              " 'is',\n",
              " 'the',\n",
              " 'perfect',\n",
              " 'length',\n",
              " 'to',\n",
              " 'wear',\n",
              " 'with',\n",
              " 'leggings',\n",
              " 'and',\n",
              " 'it',\n",
              " 'is',\n",
              " 'sleeveless',\n",
              " 'so',\n",
              " 'it',\n",
              " 'pairs',\n",
              " 'well',\n",
              " 'with',\n",
              " 'any',\n",
              " 'cardigan',\n",
              " 'love',\n",
              " 'this',\n",
              " 'shirt',\n",
              " 'I',\n",
              " 'love',\n",
              " 'tracy',\n",
              " 'reese',\n",
              " 'dresses',\n",
              " 'but',\n",
              " 'this',\n",
              " 'one',\n",
              " 'is',\n",
              " 'not',\n",
              " 'for',\n",
              " 'the',\n",
              " 'very',\n",
              " 'petite',\n",
              " 'i',\n",
              " 'am',\n",
              " 'just',\n",
              " 'under',\n",
              " '5',\n",
              " 'feet',\n",
              " 'tall',\n",
              " 'and',\n",
              " 'usually',\n",
              " 'wear',\n",
              " 'a',\n",
              " '0p',\n",
              " 'in',\n",
              " 'this',\n",
              " 'brand',\n",
              " 'this',\n",
              " 'dress',\n",
              " 'was',\n",
              " 'very',\n",
              " 'pretty',\n",
              " 'out',\n",
              " 'of',\n",
              " 'the',\n",
              " 'package',\n",
              " 'but',\n",
              " 'its',\n",
              " 'a',\n",
              " 'lot',\n",
              " 'of',\n",
              " 'dress',\n",
              " 'the',\n",
              " 'skirt',\n",
              " 'is',\n",
              " 'long',\n",
              " 'and',\n",
              " 'very',\n",
              " 'full',\n",
              " 'so',\n",
              " 'it',\n",
              " 'overwhelmed',\n",
              " 'my',\n",
              " 'small',\n",
              " 'frame',\n",
              " 'not',\n",
              " 'a',\n",
              " 'stranger',\n",
              " 'to',\n",
              " 'alterations',\n",
              " 'shortening',\n",
              " 'and',\n",
              " 'narrowing',\n",
              " 'the',\n",
              " 'skirt',\n",
              " 'would',\n",
              " 'take',\n",
              " 'away',\n",
              " 'from',\n",
              " 'the',\n",
              " 'embellishment',\n",
              " 'of',\n",
              " 'the',\n",
              " 'garment',\n",
              " 'i',\n",
              " 'love',\n",
              " 'the',\n",
              " 'color',\n",
              " 'and',\n",
              " 'the',\n",
              " 'idea',\n",
              " 'of',\n",
              " 'the',\n",
              " 'style',\n",
              " 'but',\n",
              " 'it',\n",
              " 'just',\n",
              " 'did',\n",
              " 'not',\n",
              " 'work',\n",
              " 'on',\n",
              " 'me',\n",
              " 'i',\n",
              " 'returned',\n",
              " 'this',\n",
              " 'dress',\n",
              " 'I',\n",
              " 'aded',\n",
              " 'this',\n",
              " 'in',\n",
              " 'my',\n",
              " 'basket',\n",
              " 'at',\n",
              " 'hte',\n",
              " 'last',\n",
              " 'mintue',\n",
              " 'to',\n",
              " 'see',\n",
              " 'what',\n",
              " 'it',\n",
              " 'would',\n",
              " 'look',\n",
              " 'like',\n",
              " 'in',\n",
              " 'person',\n",
              " 'store',\n",
              " 'pick',\n",
              " 'up',\n",
              " 'i',\n",
              " 'went',\n",
              " 'with',\n",
              " 'teh',\n",
              " 'darkler',\n",
              " 'color',\n",
              " 'only',\n",
              " 'because',\n",
              " 'i',\n",
              " 'am',\n",
              " 'so',\n",
              " 'pale',\n",
              " 'hte',\n",
              " 'color',\n",
              " 'is',\n",
              " 'really',\n",
              " 'gorgeous',\n",
              " 'and',\n",
              " 'turns',\n",
              " 'out',\n",
              " 'it',\n",
              " 'mathced',\n",
              " 'everythiing',\n",
              " 'i',\n",
              " 'was',\n",
              " 'trying',\n",
              " 'on',\n",
              " 'with',\n",
              " 'it',\n",
              " 'prefectly',\n",
              " 'it',\n",
              " 'is',\n",
              " 'a',\n",
              " 'little',\n",
              " 'baggy',\n",
              " 'on',\n",
              " 'me',\n",
              " 'and',\n",
              " 'hte',\n",
              " 'xs',\n",
              " 'is',\n",
              " 'hte',\n",
              " 'msallet',\n",
              " 'size',\n",
              " 'bummer',\n",
              " 'no',\n",
              " 'petite',\n",
              " 'i',\n",
              " 'decided',\n",
              " 'to',\n",
              " 'jkeep',\n",
              " 'it',\n",
              " 'though',\n",
              " 'because',\n",
              " 'as',\n",
              " 'i',\n",
              " 'said',\n",
              " 'it',\n",
              " 'matvehd',\n",
              " 'everything',\n",
              " 'my',\n",
              " 'ejans',\n",
              " 'pants',\n",
              " 'and',\n",
              " 'the',\n",
              " '3',\n",
              " 'skirts',\n",
              " 'i',\n",
              " 'waas',\n",
              " 'trying',\n",
              " 'on',\n",
              " 'of',\n",
              " 'which',\n",
              " 'i',\n",
              " 'kept',\n",
              " 'all',\n",
              " 'oops',\n",
              " 'I',\n",
              " 'ordered',\n",
              " 'this',\n",
              " 'in',\n",
              " 'carbon',\n",
              " 'for',\n",
              " 'store',\n",
              " 'pick',\n",
              " 'up',\n",
              " 'and',\n",
              " 'had',\n",
              " 'a',\n",
              " 'ton',\n",
              " 'of',\n",
              " 'stuff',\n",
              " 'as',\n",
              " 'always',\n",
              " 'to',\n",
              " 'try',\n",
              " 'on',\n",
              " 'and',\n",
              " 'used',\n",
              " 'this',\n",
              " 'top',\n",
              " 'to',\n",
              " 'pair',\n",
              " 'skirts',\n",
              " 'and',\n",
              " 'pants',\n",
              " 'everything',\n",
              " 'went',\n",
              " 'with',\n",
              " 'it',\n",
              " 'the',\n",
              " 'color',\n",
              " 'is',\n",
              " 'really',\n",
              " 'nice',\n",
              " 'charcoal',\n",
              " 'with',\n",
              " 'shimmer',\n",
              " 'and',\n",
              " 'went',\n",
              " 'well',\n",
              " 'with',\n",
              " 'pencil',\n",
              " 'skirts',\n",
              " 'flare',\n",
              " 'pants',\n",
              " 'etc',\n",
              " 'my',\n",
              " 'only',\n",
              " 'compaint',\n",
              " 'is',\n",
              " 'it',\n",
              " 'is',\n",
              " 'a',\n",
              " 'bit',\n",
              " 'big',\n",
              " 'sleeves',\n",
              " 'are',\n",
              " 'long',\n",
              " 'and',\n",
              " 'it',\n",
              " 'does',\n",
              " 'n t',\n",
              " 'go',\n",
              " 'in',\n",
              " 'petite',\n",
              " 'also',\n",
              " 'a',\n",
              " 'bit',\n",
              " 'loose',\n",
              " 'for',\n",
              " 'me',\n",
              " 'but',\n",
              " 'no',\n",
              " 'xxs',\n",
              " '...',\n",
              " 'so',\n",
              " 'i',\n",
              " 'kept',\n",
              " 'it',\n",
              " 'and',\n",
              " 'wil',\n",
              " 'ldecide',\n",
              " 'later',\n",
              " 'since',\n",
              " 'the',\n",
              " 'light',\n",
              " 'color',\n",
              " 'is',\n",
              " 'already',\n",
              " 'sold',\n",
              " 'out',\n",
              " 'in',\n",
              " 'hte',\n",
              " 'smallest',\n",
              " 'size',\n",
              " '...',\n",
              " 'I',\n",
              " 'love',\n",
              " 'this',\n",
              " 'dress',\n",
              " 'i',\n",
              " 'usually',\n",
              " 'get',\n",
              " 'an',\n",
              " 'xs',\n",
              " 'but',\n",
              " 'it',\n",
              " 'runs',\n",
              " 'a',\n",
              " 'little',\n",
              " 'snug',\n",
              " 'in',\n",
              " 'bust',\n",
              " 'so',\n",
              " 'i',\n",
              " 'ordered',\n",
              " 'up',\n",
              " 'a',\n",
              " 'size',\n",
              " 'very',\n",
              " 'flattering',\n",
              " 'and',\n",
              " 'feminine',\n",
              " 'with',\n",
              " 'the',\n",
              " 'usual',\n",
              " 'retailer',\n",
              " 'flair',\n",
              " 'for',\n",
              " 'style',\n",
              " 'I',\n",
              " ' m',\n",
              " '5',\n",
              " '5',\n",
              " 'and',\n",
              " '125',\n",
              " 'lbs',\n",
              " 'i',\n",
              " 'ordered',\n",
              " 'the',\n",
              " 's',\n",
              " 'petite',\n",
              " 'to',\n",
              " 'make',\n",
              " 'sure',\n",
              " 'the',\n",
              " 'length',\n",
              " 'was',\n",
              " 'n t',\n",
              " 'too',\n",
              " 'long',\n",
              " 'i',\n",
              " 'typically',\n",
              " 'wear',\n",
              " 'an',\n",
              " 'xs',\n",
              " 'regular',\n",
              " 'in',\n",
              " 'retailer',\n",
              " 'dresses',\n",
              " 'if',\n",
              " 'you',\n",
              " ' re',\n",
              " 'less',\n",
              " 'busty',\n",
              " '34b',\n",
              " 'cup',\n",
              " 'or',\n",
              " 'smaller',\n",
              " 'a',\n",
              " 's',\n",
              " 'petite',\n",
              " 'will',\n",
              " 'fit',\n",
              " 'you',\n",
              " 'perfectly',\n",
              " 'snug',\n",
              " 'but',\n",
              " 'not',\n",
              " 'tight',\n",
              " 'i',\n",
              " 'love',\n",
              " 'that',\n",
              " 'i',\n",
              " 'could',\n",
              " 'dress',\n",
              " 'it',\n",
              " 'up',\n",
              " 'for',\n",
              " 'a',\n",
              " 'party',\n",
              " 'or',\n",
              " 'down',\n",
              " 'for',\n",
              " 'work',\n",
              " 'i',\n",
              " 'love',\n",
              " 'that',\n",
              " 'the',\n",
              " 'tulle',\n",
              " 'is',\n",
              " 'longer',\n",
              " 'then',\n",
              " 'the',\n",
              " 'fabric',\n",
              " 'underneath',\n",
              " 'Dress',\n",
              " 'runs',\n",
              " 'small',\n",
              " 'esp',\n",
              " 'where',\n",
              " 'the',\n",
              " 'zipper',\n",
              " 'area',\n",
              " 'runs',\n",
              " 'i',\n",
              " 'ordered',\n",
              " 'the',\n",
              " 'sp',\n",
              " 'which',\n",
              " 'typically',\n",
              " 'fits',\n",
              " 'me',\n",
              " 'and',\n",
              " 'it',\n",
              " 'was',\n",
              " 'very',\n",
              " 'tight',\n",
              " 'the',\n",
              " 'material',\n",
              " 'on',\n",
              " 'the',\n",
              " 'top',\n",
              " 'looks',\n",
              " 'and',\n",
              " 'feels',\n",
              " 'very',\n",
              " 'cheap',\n",
              " 'that',\n",
              " 'even',\n",
              " 'just',\n",
              " 'pulling',\n",
              " 'on',\n",
              " 'it',\n",
              " 'will',\n",
              " 'cause',\n",
              " 'it',\n",
              " 'to',\n",
              " 'rip',\n",
              " 'the',\n",
              " 'fabric',\n",
              " 'pretty',\n",
              " 'disappointed',\n",
              " 'as',\n",
              " 'it',\n",
              " 'was',\n",
              " 'going',\n",
              " 'to',\n",
              " 'be',\n",
              " 'my',\n",
              " 'christmas',\n",
              " 'dress',\n",
              " 'this',\n",
              " 'year',\n",
              " 'needless',\n",
              " 'to',\n",
              " 'say',\n",
              " 'it',\n",
              " 'will',\n",
              " 'be',\n",
              " 'going',\n",
              " 'back',\n",
              " 'This',\n",
              " 'dress',\n",
              " 'is',\n",
              " 'perfection',\n",
              " 'so',\n",
              " 'pretty',\n",
              " 'and',\n",
              " 'flattering',\n",
              " 'More',\n",
              " 'and',\n",
              " 'more',\n",
              " 'i',\n",
              " 'find',\n",
              " 'myself',\n",
              " 'reliant',\n",
              " 'on',\n",
              " 'the',\n",
              " 'reviews',\n",
              " 'written',\n",
              " 'by',\n",
              " 'savvy',\n",
              " 'shoppers',\n",
              " 'before',\n",
              " 'me',\n",
              " 'and',\n",
              " 'for',\n",
              " 'the',\n",
              " 'most',\n",
              " 'past',\n",
              " 'they',\n",
              " 'are',\n",
              " 'right',\n",
              " 'on',\n",
              " 'in',\n",
              " 'their',\n",
              " 'estimation',\n",
              " 'of',\n",
              " 'the',\n",
              " 'product',\n",
              " 'in',\n",
              " 'the',\n",
              " 'case',\n",
              " 'of',\n",
              " 'this',\n",
              " 'dress-if',\n",
              " 'it',\n",
              " 'had',\n",
              " 'not',\n",
              " 'been',\n",
              " 'for',\n",
              " 'the',\n",
              " 'reveiws-i',\n",
              " 'doubt',\n",
              " 'i',\n",
              " 'would',\n",
              " 'have',\n",
              " 'even',\n",
              " 'tried',\n",
              " 'this',\n",
              " 'the',\n",
              " 'dress',\n",
              " 'is',\n",
              " 'beautifully',\n",
              " 'made',\n",
              " 'lined',\n",
              " 'and',\n",
              " 'reminiscent',\n",
              " 'of',\n",
              " 'the',\n",
              " 'old',\n",
              " 'retailer',\n",
              " 'quality',\n",
              " 'it',\n",
              " 'is',\n",
              " 'lined',\n",
              " 'in',\n",
              " 'the',\n",
              " 'solid',\n",
              " 'periwinkle-colored',\n",
              " 'fabric',\n",
              " 'that',\n",
              " 'matches',\n",
              " 'the',\n",
              " 'outer',\n",
              " 'fabric',\n",
              " 'print',\n",
              " 'tts',\n",
              " 'and',\n",
              " 'very',\n",
              " 'form-fitting',\n",
              " 'falls',\n",
              " 'just',\n",
              " 'above',\n",
              " 'the',\n",
              " 'knee',\n",
              " 'and',\n",
              " 'does',\n",
              " 'not',\n",
              " 'rid',\n",
              " 'Bought',\n",
              " 'the',\n",
              " 'black',\n",
              " 'xs',\n",
              " 'to',\n",
              " 'go',\n",
              " 'under',\n",
              " 'the',\n",
              " 'larkspur',\n",
              " 'midi',\n",
              " 'dress',\n",
              " 'because',\n",
              " 'they',\n",
              " 'did',\n",
              " 'n t',\n",
              " 'bother',\n",
              " 'lining',\n",
              " 'the',\n",
              " 'skirt',\n",
              " 'portion',\n",
              " 'grrrrrrrrrrr',\n",
              " 'my',\n",
              " 'stats',\n",
              " 'are',\n",
              " '34a-28/29-36',\n",
              " 'and',\n",
              " 'the',\n",
              " 'xs',\n",
              " 'fit',\n",
              " 'very',\n",
              " 'smoothly',\n",
              " 'around',\n",
              " 'the',\n",
              " 'chest',\n",
              " 'and',\n",
              " 'was',\n",
              " 'flowy',\n",
              " 'around',\n",
              " 'my',\n",
              " 'lower',\n",
              " 'half',\n",
              " 'so',\n",
              " 'i',\n",
              " 'would',\n",
              " 'say',\n",
              " 'it',\n",
              " ' s',\n",
              " 'running',\n",
              " 'big',\n",
              " 'the',\n",
              " 'straps',\n",
              " 'are',\n",
              " 'very',\n",
              " 'pretty',\n",
              " 'and',\n",
              " 'it',\n",
              " 'could',\n",
              " 'easily',\n",
              " 'be',\n",
              " 'nightwear',\n",
              " 'too',\n",
              " 'i',\n",
              " ' m',\n",
              " '5',\n",
              " '6',\n",
              " 'and',\n",
              " 'it',\n",
              " 'came',\n",
              " 'to',\n",
              " 'just',\n",
              " 'below',\n",
              " 'my',\n",
              " 'knees',\n",
              " 'This',\n",
              " 'is',\n",
              " 'a',\n",
              " 'nice',\n",
              " 'choice',\n",
              " 'for',\n",
              " 'holiday',\n",
              " 'gatherings',\n",
              " 'i',\n",
              " 'like',\n",
              " 'that',\n",
              " 'the',\n",
              " 'length',\n",
              " 'grazes',\n",
              " 'the',\n",
              " 'knee',\n",
              " 'so',\n",
              " 'it',\n",
              " 'is',\n",
              " 'conservative',\n",
              " 'enough',\n",
              " 'for',\n",
              " 'office',\n",
              " 'related',\n",
              " 'gatherings',\n",
              " 'the',\n",
              " 'size',\n",
              " 'small',\n",
              " 'fit',\n",
              " 'me',\n",
              " 'well',\n",
              " 'i',\n",
              " 'am',\n",
              " 'usually',\n",
              " 'a',\n",
              " 'size',\n",
              " '2/4',\n",
              " 'with',\n",
              " 'a',\n",
              " 'small',\n",
              " 'bust',\n",
              " 'in',\n",
              " 'my',\n",
              " 'opinion',\n",
              " 'it',\n",
              " 'runs',\n",
              " 'small',\n",
              " 'and',\n",
              " 'those',\n",
              " 'with',\n",
              " 'larger',\n",
              " 'busts',\n",
              " 'will',\n",
              " 'definitely',\n",
              " 'have',\n",
              " 'to',\n",
              " 'size',\n",
              " 'up',\n",
              " 'but',\n",
              " 'then',\n",
              " 'perhaps',\n",
              " 'the',\n",
              " 'waist',\n",
              " 'will',\n",
              " 'be',\n",
              " 'too',\n",
              " 'big',\n",
              " 'the',\n",
              " 'problem',\n",
              " 'with',\n",
              " 'this',\n",
              " 'dress',\n",
              " 'is',\n",
              " 'the',\n",
              " 'quality',\n",
              " 'the',\n",
              " 'fabrics',\n",
              " 'are',\n",
              " 'terrible',\n",
              " 'the',\n",
              " 'delicate',\n",
              " 'netting',\n",
              " 'type',\n",
              " 'fabric',\n",
              " 'on',\n",
              " 'the',\n",
              " 'top',\n",
              " 'layer',\n",
              " 'of',\n",
              " 'skirt',\n",
              " 'got',\n",
              " 'stuck',\n",
              " 'in',\n",
              " 'the',\n",
              " 'zip',\n",
              " 'I',\n",
              " 'took',\n",
              " 'these',\n",
              " 'out',\n",
              " 'of',\n",
              " 'the',\n",
              " 'package',\n",
              " 'and',\n",
              " 'wanted',\n",
              " 'them',\n",
              " 'to',\n",
              " 'fit',\n",
              " 'so',\n",
              " 'badly',\n",
              " 'but',\n",
              " 'i',\n",
              " 'could',\n",
              " 'tell',\n",
              " 'before',\n",
              " 'i',\n",
              " 'put',\n",
              " 'them',\n",
              " 'on',\n",
              " 'that',\n",
              " 'they',\n",
              " 'would',\n",
              " 'n t',\n",
              " 'these',\n",
              " 'are',\n",
              " 'for',\n",
              " 'an',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n"
      ],
      "metadata": {
        "id": "X-4pEue1NT_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_words = list(sent_to_words(data))\n",
        "data_words = [dw for dw in data_words if len(dw)>0]"
      ],
      "metadata": {
        "id": "h4orGDYDNbxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyT1IB9hOr2g",
        "outputId": "d72a320c-7fc0-481a-82a2-a099ed357994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['absolutely'],\n",
              " ['wonderful'],\n",
              " ['silky'],\n",
              " ['and'],\n",
              " ['sexy'],\n",
              " ['and'],\n",
              " ['comfortable'],\n",
              " ['love'],\n",
              " ['this'],\n",
              " ['dress'],\n",
              " ['it'],\n",
              " ['sooo'],\n",
              " ['pretty'],\n",
              " ['happened'],\n",
              " ['to'],\n",
              " ['find'],\n",
              " ['it'],\n",
              " ['in'],\n",
              " ['store'],\n",
              " ['and'],\n",
              " ['glad'],\n",
              " ['did'],\n",
              " ['bc'],\n",
              " ['never'],\n",
              " ['would'],\n",
              " ['have'],\n",
              " ['ordered'],\n",
              " ['it'],\n",
              " ['online'],\n",
              " ['bc'],\n",
              " ['it'],\n",
              " ['petite'],\n",
              " ['bought'],\n",
              " ['petite'],\n",
              " ['and'],\n",
              " ['am'],\n",
              " ['love'],\n",
              " ['the'],\n",
              " ['length'],\n",
              " ['on'],\n",
              " ['me'],\n",
              " ['hits'],\n",
              " ['just'],\n",
              " ['little'],\n",
              " ['below'],\n",
              " ['the'],\n",
              " ['knee'],\n",
              " ['would'],\n",
              " ['definitely'],\n",
              " ['be'],\n",
              " ['true'],\n",
              " ['midi'],\n",
              " ['on'],\n",
              " ['someone'],\n",
              " ['who'],\n",
              " ['is'],\n",
              " ['truly'],\n",
              " ['petite'],\n",
              " ['had'],\n",
              " ['such'],\n",
              " ['high'],\n",
              " ['hopes'],\n",
              " ['for'],\n",
              " ['this'],\n",
              " ['dress'],\n",
              " ['and'],\n",
              " ['really'],\n",
              " ['wanted'],\n",
              " ['it'],\n",
              " ['to'],\n",
              " ['work'],\n",
              " ['for'],\n",
              " ['me'],\n",
              " ['initially'],\n",
              " ['ordered'],\n",
              " ['the'],\n",
              " ['petite'],\n",
              " ['small'],\n",
              " ['my'],\n",
              " ['usual'],\n",
              " ['size'],\n",
              " ['but'],\n",
              " ['found'],\n",
              " ['this'],\n",
              " ['to'],\n",
              " ['be'],\n",
              " ['outrageously'],\n",
              " ['small'],\n",
              " ['so'],\n",
              " ['small'],\n",
              " ['in'],\n",
              " ['fact'],\n",
              " ['that'],\n",
              " ['could'],\n",
              " ['not'],\n",
              " ['zip'],\n",
              " ['it'],\n",
              " ['up'],\n",
              " ['reordered'],\n",
              " ['it'],\n",
              " ['in'],\n",
              " ['petite'],\n",
              " ['medium'],\n",
              " ['which'],\n",
              " ['was'],\n",
              " ['just'],\n",
              " ['ok'],\n",
              " ['overall'],\n",
              " ['the'],\n",
              " ['top'],\n",
              " ['half'],\n",
              " ['was'],\n",
              " ['comfortable'],\n",
              " ['and'],\n",
              " ['fit'],\n",
              " ['nicely'],\n",
              " ['but'],\n",
              " ['the'],\n",
              " ['bottom'],\n",
              " ['half'],\n",
              " ['had'],\n",
              " ['very'],\n",
              " ['tight'],\n",
              " ['under'],\n",
              " ['layer'],\n",
              " ['and'],\n",
              " ['several'],\n",
              " ['somewhat'],\n",
              " ['cheap'],\n",
              " ['net'],\n",
              " ['over'],\n",
              " ['layers'],\n",
              " ['imo'],\n",
              " ['major'],\n",
              " ['design'],\n",
              " ['flaw'],\n",
              " ['was'],\n",
              " ['the'],\n",
              " ['net'],\n",
              " ['over'],\n",
              " ['layer'],\n",
              " ['sewn'],\n",
              " ['directly'],\n",
              " ['into'],\n",
              " ['the'],\n",
              " ['zipper'],\n",
              " ['it'],\n",
              " ['love'],\n",
              " ['love'],\n",
              " ['love'],\n",
              " ['this'],\n",
              " ['jumpsuit'],\n",
              " ['it'],\n",
              " ['fun'],\n",
              " ['flirty'],\n",
              " ['and'],\n",
              " ['fabulous'],\n",
              " ['every'],\n",
              " ['time'],\n",
              " ['wear'],\n",
              " ['it'],\n",
              " ['get'],\n",
              " ['nothing'],\n",
              " ['but'],\n",
              " ['great'],\n",
              " ['compliments'],\n",
              " ['this'],\n",
              " ['shirt'],\n",
              " ['is'],\n",
              " ['very'],\n",
              " ['flattering'],\n",
              " ['to'],\n",
              " ['all'],\n",
              " ['due'],\n",
              " ['to'],\n",
              " ['the'],\n",
              " ['adjustable'],\n",
              " ['front'],\n",
              " ['tie'],\n",
              " ['it'],\n",
              " ['is'],\n",
              " ['the'],\n",
              " ['perfect'],\n",
              " ['length'],\n",
              " ['to'],\n",
              " ['wear'],\n",
              " ['with'],\n",
              " ['leggings'],\n",
              " ['and'],\n",
              " ['it'],\n",
              " ['is'],\n",
              " ['sleeveless'],\n",
              " ['so'],\n",
              " ['it'],\n",
              " ['pairs'],\n",
              " ['well'],\n",
              " ['with'],\n",
              " ['any'],\n",
              " ['cardigan'],\n",
              " ['love'],\n",
              " ['this'],\n",
              " ['shirt'],\n",
              " ['love'],\n",
              " ['tracy'],\n",
              " ['reese'],\n",
              " ['dresses'],\n",
              " ['but'],\n",
              " ['this'],\n",
              " ['one'],\n",
              " ['is'],\n",
              " ['not'],\n",
              " ['for'],\n",
              " ['the'],\n",
              " ['very'],\n",
              " ['petite'],\n",
              " ['am'],\n",
              " ['just'],\n",
              " ['under'],\n",
              " ['feet'],\n",
              " ['tall'],\n",
              " ['and'],\n",
              " ['usually'],\n",
              " ['wear'],\n",
              " ['in'],\n",
              " ['this'],\n",
              " ['brand'],\n",
              " ['this'],\n",
              " ['dress'],\n",
              " ['was'],\n",
              " ['very'],\n",
              " ['pretty'],\n",
              " ['out'],\n",
              " ['of'],\n",
              " ['the'],\n",
              " ['package'],\n",
              " ['but'],\n",
              " ['its'],\n",
              " ['lot'],\n",
              " ['of'],\n",
              " ['dress'],\n",
              " ['the'],\n",
              " ['skirt'],\n",
              " ['is'],\n",
              " ['long'],\n",
              " ['and'],\n",
              " ['very'],\n",
              " ['full'],\n",
              " ['so'],\n",
              " ['it'],\n",
              " ['overwhelmed'],\n",
              " ['my'],\n",
              " ['small'],\n",
              " ['frame'],\n",
              " ['not'],\n",
              " ['stranger'],\n",
              " ['to'],\n",
              " ['alterations'],\n",
              " ['shortening'],\n",
              " ['and'],\n",
              " ['narrowing'],\n",
              " ['the'],\n",
              " ['skirt'],\n",
              " ['would'],\n",
              " ['take'],\n",
              " ['away'],\n",
              " ['from'],\n",
              " ['the'],\n",
              " ['embellishment'],\n",
              " ['of'],\n",
              " ['the'],\n",
              " ['garment'],\n",
              " ['love'],\n",
              " ['the'],\n",
              " ['color'],\n",
              " ['and'],\n",
              " ['the'],\n",
              " ['idea'],\n",
              " ['of'],\n",
              " ['the'],\n",
              " ['style'],\n",
              " ['but'],\n",
              " ['it'],\n",
              " ['just'],\n",
              " ['did'],\n",
              " ['not'],\n",
              " ['work'],\n",
              " ['on'],\n",
              " ['me'],\n",
              " ['returned'],\n",
              " ['this'],\n",
              " ['dress'],\n",
              " ['aded'],\n",
              " ['this'],\n",
              " ['in'],\n",
              " ['my'],\n",
              " ['basket'],\n",
              " ['at'],\n",
              " ['hte'],\n",
              " ['last'],\n",
              " ['mintue'],\n",
              " ['to'],\n",
              " ['see'],\n",
              " ['what'],\n",
              " ['it'],\n",
              " ['would'],\n",
              " ['look'],\n",
              " ['like'],\n",
              " ['in'],\n",
              " ['person'],\n",
              " ['store'],\n",
              " ['pick'],\n",
              " ['up'],\n",
              " ['went'],\n",
              " ['with'],\n",
              " ['teh'],\n",
              " ['darkler'],\n",
              " ['color'],\n",
              " ['only'],\n",
              " ['because'],\n",
              " ['am'],\n",
              " ['so'],\n",
              " ['pale'],\n",
              " ['hte'],\n",
              " ['color'],\n",
              " ['is'],\n",
              " ['really'],\n",
              " ['gorgeous'],\n",
              " ['and'],\n",
              " ['turns'],\n",
              " ['out'],\n",
              " ['it'],\n",
              " ['mathced'],\n",
              " ['everythiing'],\n",
              " ['was'],\n",
              " ['trying'],\n",
              " ['on'],\n",
              " ['with'],\n",
              " ['it'],\n",
              " ['prefectly'],\n",
              " ['it'],\n",
              " ['is'],\n",
              " ['little'],\n",
              " ['baggy'],\n",
              " ['on'],\n",
              " ['me'],\n",
              " ['and'],\n",
              " ['hte'],\n",
              " ['xs'],\n",
              " ['is'],\n",
              " ['hte'],\n",
              " ['msallet'],\n",
              " ['size'],\n",
              " ['bummer'],\n",
              " ['no'],\n",
              " ['petite'],\n",
              " ['decided'],\n",
              " ['to'],\n",
              " ['jkeep'],\n",
              " ['it'],\n",
              " ['though'],\n",
              " ['because'],\n",
              " ['as'],\n",
              " ['said'],\n",
              " ['it'],\n",
              " ['matvehd'],\n",
              " ['everything'],\n",
              " ['my'],\n",
              " ['ejans'],\n",
              " ['pants'],\n",
              " ['and'],\n",
              " ['the'],\n",
              " ['skirts'],\n",
              " ['waas'],\n",
              " ['trying'],\n",
              " ['on'],\n",
              " ['of'],\n",
              " ['which'],\n",
              " ['kept'],\n",
              " ['all'],\n",
              " ['oops'],\n",
              " ['ordered'],\n",
              " ['this'],\n",
              " ['in'],\n",
              " ['carbon'],\n",
              " ['for'],\n",
              " ['store'],\n",
              " ['pick'],\n",
              " ['up'],\n",
              " ['and'],\n",
              " ['had'],\n",
              " ['ton'],\n",
              " ['of'],\n",
              " ['stuff'],\n",
              " ['as'],\n",
              " ['always'],\n",
              " ['to'],\n",
              " ['try'],\n",
              " ['on'],\n",
              " ['and'],\n",
              " ['used'],\n",
              " ['this'],\n",
              " ['top'],\n",
              " ['to'],\n",
              " ['pair'],\n",
              " ['skirts'],\n",
              " ['and'],\n",
              " ['pants'],\n",
              " ['everything'],\n",
              " ['went'],\n",
              " ['with'],\n",
              " ['it'],\n",
              " ['the'],\n",
              " ['color'],\n",
              " ['is'],\n",
              " ['really'],\n",
              " ['nice'],\n",
              " ['charcoal'],\n",
              " ['with'],\n",
              " ['shimmer'],\n",
              " ['and'],\n",
              " ['went'],\n",
              " ['well'],\n",
              " ['with'],\n",
              " ['pencil'],\n",
              " ['skirts'],\n",
              " ['flare'],\n",
              " ['pants'],\n",
              " ['etc'],\n",
              " ['my'],\n",
              " ['only'],\n",
              " ['compaint'],\n",
              " ['is'],\n",
              " ['it'],\n",
              " ['is'],\n",
              " ['bit'],\n",
              " ['big'],\n",
              " ['sleeves'],\n",
              " ['are'],\n",
              " ['long'],\n",
              " ['and'],\n",
              " ['it'],\n",
              " ['does'],\n",
              " ['go'],\n",
              " ['in'],\n",
              " ['petite'],\n",
              " ['also'],\n",
              " ['bit'],\n",
              " ['loose'],\n",
              " ['for'],\n",
              " ['me'],\n",
              " ['but'],\n",
              " ['no'],\n",
              " ['xxs'],\n",
              " ['so'],\n",
              " ['kept'],\n",
              " ['it'],\n",
              " ['and'],\n",
              " ['wil'],\n",
              " ['ldecide'],\n",
              " ['later'],\n",
              " ['since'],\n",
              " ['the'],\n",
              " ['light'],\n",
              " ['color'],\n",
              " ['is'],\n",
              " ['already'],\n",
              " ['sold'],\n",
              " ['out'],\n",
              " ['in'],\n",
              " ['hte'],\n",
              " ['smallest'],\n",
              " ['size'],\n",
              " ['love'],\n",
              " ['this'],\n",
              " ['dress'],\n",
              " ['usually'],\n",
              " ['get'],\n",
              " ['an'],\n",
              " ['xs'],\n",
              " ['but'],\n",
              " ['it'],\n",
              " ['runs'],\n",
              " ['little'],\n",
              " ['snug'],\n",
              " ['in'],\n",
              " ['bust'],\n",
              " ['so'],\n",
              " ['ordered'],\n",
              " ['up'],\n",
              " ['size'],\n",
              " ['very'],\n",
              " ['flattering'],\n",
              " ['and'],\n",
              " ['feminine'],\n",
              " ['with'],\n",
              " ['the'],\n",
              " ['usual'],\n",
              " ['retailer'],\n",
              " ['flair'],\n",
              " ['for'],\n",
              " ['style'],\n",
              " ['and'],\n",
              " ['lbs'],\n",
              " ['ordered'],\n",
              " ['the'],\n",
              " ['petite'],\n",
              " ['to'],\n",
              " ['make'],\n",
              " ['sure'],\n",
              " ['the'],\n",
              " ['length'],\n",
              " ['was'],\n",
              " ['too'],\n",
              " ['long'],\n",
              " ['typically'],\n",
              " ['wear'],\n",
              " ['an'],\n",
              " ['xs'],\n",
              " ['regular'],\n",
              " ['in'],\n",
              " ['retailer'],\n",
              " ['dresses'],\n",
              " ['if'],\n",
              " ['you'],\n",
              " ['re'],\n",
              " ['less'],\n",
              " ['busty'],\n",
              " ['cup'],\n",
              " ['or'],\n",
              " ['smaller'],\n",
              " ['petite'],\n",
              " ['will'],\n",
              " ['fit'],\n",
              " ['you'],\n",
              " ['perfectly'],\n",
              " ['snug'],\n",
              " ['but'],\n",
              " ['not'],\n",
              " ['tight'],\n",
              " ['love'],\n",
              " ['that'],\n",
              " ['could'],\n",
              " ['dress'],\n",
              " ['it'],\n",
              " ['up'],\n",
              " ['for'],\n",
              " ['party'],\n",
              " ['or'],\n",
              " ['down'],\n",
              " ['for'],\n",
              " ['work'],\n",
              " ['love'],\n",
              " ['that'],\n",
              " ['the'],\n",
              " ['tulle'],\n",
              " ['is'],\n",
              " ['longer'],\n",
              " ['then'],\n",
              " ['the'],\n",
              " ['fabric'],\n",
              " ['underneath'],\n",
              " ['dress'],\n",
              " ['runs'],\n",
              " ['small'],\n",
              " ['esp'],\n",
              " ['where'],\n",
              " ['the'],\n",
              " ['zipper'],\n",
              " ['area'],\n",
              " ['runs'],\n",
              " ['ordered'],\n",
              " ['the'],\n",
              " ['sp'],\n",
              " ['which'],\n",
              " ['typically'],\n",
              " ['fits'],\n",
              " ['me'],\n",
              " ['and'],\n",
              " ['it'],\n",
              " ['was'],\n",
              " ['very'],\n",
              " ['tight'],\n",
              " ['the'],\n",
              " ['material'],\n",
              " ['on'],\n",
              " ['the'],\n",
              " ['top'],\n",
              " ['looks'],\n",
              " ['and'],\n",
              " ['feels'],\n",
              " ['very'],\n",
              " ['cheap'],\n",
              " ['that'],\n",
              " ['even'],\n",
              " ['just'],\n",
              " ['pulling'],\n",
              " ['on'],\n",
              " ['it'],\n",
              " ['will'],\n",
              " ['cause'],\n",
              " ['it'],\n",
              " ['to'],\n",
              " ['rip'],\n",
              " ['the'],\n",
              " ['fabric'],\n",
              " ['pretty'],\n",
              " ['disappointed'],\n",
              " ['as'],\n",
              " ['it'],\n",
              " ['was'],\n",
              " ['going'],\n",
              " ['to'],\n",
              " ['be'],\n",
              " ['my'],\n",
              " ['christmas'],\n",
              " ['dress'],\n",
              " ['this'],\n",
              " ['year'],\n",
              " ['needless'],\n",
              " ['to'],\n",
              " ['say'],\n",
              " ['it'],\n",
              " ['will'],\n",
              " ['be'],\n",
              " ['going'],\n",
              " ['back'],\n",
              " ['this'],\n",
              " ['dress'],\n",
              " ['is'],\n",
              " ['perfection'],\n",
              " ['so'],\n",
              " ['pretty'],\n",
              " ['and'],\n",
              " ['flattering'],\n",
              " ['more'],\n",
              " ['and'],\n",
              " ['more'],\n",
              " ['find'],\n",
              " ['myself'],\n",
              " ['reliant'],\n",
              " ['on'],\n",
              " ['the'],\n",
              " ['reviews'],\n",
              " ['written'],\n",
              " ['by'],\n",
              " ['savvy'],\n",
              " ['shoppers'],\n",
              " ['before'],\n",
              " ['me'],\n",
              " ['and'],\n",
              " ['for'],\n",
              " ['the'],\n",
              " ['most'],\n",
              " ['past'],\n",
              " ['they'],\n",
              " ['are'],\n",
              " ['right'],\n",
              " ['on'],\n",
              " ['in'],\n",
              " ['their'],\n",
              " ['estimation'],\n",
              " ['of'],\n",
              " ['the'],\n",
              " ['product'],\n",
              " ['in'],\n",
              " ['the'],\n",
              " ['case'],\n",
              " ['of'],\n",
              " ['this'],\n",
              " ['dress', 'if'],\n",
              " ['it'],\n",
              " ['had'],\n",
              " ['not'],\n",
              " ['been'],\n",
              " ['for'],\n",
              " ['the'],\n",
              " ['reveiws'],\n",
              " ['doubt'],\n",
              " ['would'],\n",
              " ['have'],\n",
              " ['even'],\n",
              " ['tried'],\n",
              " ['this'],\n",
              " ['the'],\n",
              " ['dress'],\n",
              " ['is'],\n",
              " ['beautifully'],\n",
              " ['made'],\n",
              " ['lined'],\n",
              " ['and'],\n",
              " ['reminiscent'],\n",
              " ['of'],\n",
              " ['the'],\n",
              " ['old'],\n",
              " ['retailer'],\n",
              " ['quality'],\n",
              " ['it'],\n",
              " ['is'],\n",
              " ['lined'],\n",
              " ['in'],\n",
              " ['the'],\n",
              " ['solid'],\n",
              " ['periwinkle', 'colored'],\n",
              " ['fabric'],\n",
              " ['that'],\n",
              " ['matches'],\n",
              " ['the'],\n",
              " ['outer'],\n",
              " ['fabric'],\n",
              " ['print'],\n",
              " ['tts'],\n",
              " ['and'],\n",
              " ['very'],\n",
              " ['form', 'fitting'],\n",
              " ['falls'],\n",
              " ['just'],\n",
              " ['above'],\n",
              " ['the'],\n",
              " ['knee'],\n",
              " ['and'],\n",
              " ['does'],\n",
              " ['not'],\n",
              " ['rid'],\n",
              " ['bought'],\n",
              " ['the'],\n",
              " ['black'],\n",
              " ['xs'],\n",
              " ['to'],\n",
              " ['go'],\n",
              " ['under'],\n",
              " ['the'],\n",
              " ['larkspur'],\n",
              " ['midi'],\n",
              " ['dress'],\n",
              " ['because'],\n",
              " ['they'],\n",
              " ['did'],\n",
              " ['bother'],\n",
              " ['lining'],\n",
              " ['the'],\n",
              " ['skirt'],\n",
              " ['portion'],\n",
              " ['grrrrrrrrrrr'],\n",
              " ['my'],\n",
              " ['stats'],\n",
              " ['are'],\n",
              " ['and'],\n",
              " ['the'],\n",
              " ['xs'],\n",
              " ['fit'],\n",
              " ['very'],\n",
              " ['smoothly'],\n",
              " ['around'],\n",
              " ['the'],\n",
              " ['chest'],\n",
              " ['and'],\n",
              " ['was'],\n",
              " ['flowy'],\n",
              " ['around'],\n",
              " ['my'],\n",
              " ['lower'],\n",
              " ['half'],\n",
              " ['so'],\n",
              " ['would'],\n",
              " ['say'],\n",
              " ['it'],\n",
              " ['running'],\n",
              " ['big'],\n",
              " ['the'],\n",
              " ['straps'],\n",
              " ['are'],\n",
              " ['very'],\n",
              " ['pretty'],\n",
              " ['and'],\n",
              " ['it'],\n",
              " ['could'],\n",
              " ['easily'],\n",
              " ['be'],\n",
              " ['nightwear'],\n",
              " ['too'],\n",
              " ['and'],\n",
              " ['it'],\n",
              " ['came'],\n",
              " ['to'],\n",
              " ['just'],\n",
              " ['below'],\n",
              " ['my'],\n",
              " ['knees'],\n",
              " ['this'],\n",
              " ['is'],\n",
              " ['nice'],\n",
              " ['choice'],\n",
              " ['for'],\n",
              " ['holiday'],\n",
              " ['gatherings'],\n",
              " ['like'],\n",
              " ['that'],\n",
              " ['the'],\n",
              " ['length'],\n",
              " ['grazes'],\n",
              " ['the'],\n",
              " ['knee'],\n",
              " ['so'],\n",
              " ['it'],\n",
              " ['is'],\n",
              " ['conservative'],\n",
              " ['enough'],\n",
              " ['for'],\n",
              " ['office'],\n",
              " ['related'],\n",
              " ['gatherings'],\n",
              " ['the'],\n",
              " ['size'],\n",
              " ['small'],\n",
              " ['fit'],\n",
              " ['me'],\n",
              " ['well'],\n",
              " ['am'],\n",
              " ['usually'],\n",
              " ['size'],\n",
              " ['with'],\n",
              " ['small'],\n",
              " ['bust'],\n",
              " ['in'],\n",
              " ['my'],\n",
              " ['opinion'],\n",
              " ['it'],\n",
              " ['runs'],\n",
              " ['small'],\n",
              " ['and'],\n",
              " ['those'],\n",
              " ['with'],\n",
              " ['larger'],\n",
              " ['busts'],\n",
              " ['will'],\n",
              " ['definitely'],\n",
              " ['have'],\n",
              " ['to'],\n",
              " ['size'],\n",
              " ['up'],\n",
              " ['but'],\n",
              " ['then'],\n",
              " ['perhaps'],\n",
              " ['the'],\n",
              " ['waist'],\n",
              " ['will'],\n",
              " ['be'],\n",
              " ['too'],\n",
              " ['big'],\n",
              " ['the'],\n",
              " ['problem'],\n",
              " ['with'],\n",
              " ['this'],\n",
              " ['dress'],\n",
              " ['is'],\n",
              " ['the'],\n",
              " ['quality'],\n",
              " ['the'],\n",
              " ['fabrics'],\n",
              " ['are'],\n",
              " ['terrible'],\n",
              " ['the'],\n",
              " ['delicate'],\n",
              " ['netting'],\n",
              " ['type'],\n",
              " ['fabric'],\n",
              " ['on'],\n",
              " ['the'],\n",
              " ['top'],\n",
              " ['layer'],\n",
              " ['of'],\n",
              " ['skirt'],\n",
              " ['got'],\n",
              " ['stuck'],\n",
              " ['in'],\n",
              " ['the'],\n",
              " ['zip'],\n",
              " ['took'],\n",
              " ['these'],\n",
              " ['out'],\n",
              " ['of'],\n",
              " ['the'],\n",
              " ['package'],\n",
              " ['and'],\n",
              " ['wanted'],\n",
              " ['them'],\n",
              " ['to'],\n",
              " ['fit'],\n",
              " ['so'],\n",
              " ['badly'],\n",
              " ['but'],\n",
              " ['could'],\n",
              " ['tell'],\n",
              " ['before'],\n",
              " ['put'],\n",
              " ['them'],\n",
              " ['on'],\n",
              " ['that'],\n",
              " ['they'],\n",
              " ['would'],\n",
              " ['these'],\n",
              " ['are'],\n",
              " ['for'],\n",
              " ['an'],\n",
              " ['hour', 'glass'],\n",
              " ['figure'],\n",
              " ['am'],\n",
              " ['more'],\n",
              " ['straight'],\n",
              " ['up'],\n",
              " ['and'],\n",
              " ['down'],\n",
              " ['the'],\n",
              " ['waist'],\n",
              " ['was'],\n",
              " ['way'],\n",
              " ['too'],\n",
              " ['small'],\n",
              " ['for'],\n",
              " ['my'],\n",
              " ['body'],\n",
              " ['shape'],\n",
              " ['and'],\n",
              " ['even'],\n",
              " ['if'],\n",
              " ['sized'],\n",
              " ['up'],\n",
              " ['could'],\n",
              " ['tell'],\n",
              " ['they'],\n",
              " ['would'],\n",
              " ['still'],\n",
              " ['be'],\n",
              " ['tight'],\n",
              " ['in'],\n",
              " ['the'],\n",
              " ['waist'],\n",
              " ['and'],\n",
              " ['too'],\n",
              " ['roomy'],\n",
              " ['in'],\n",
              " ['the'],\n",
              " ['hips'],\n",
              " ['for'],\n",
              " ['me'],\n",
              " ['that'],\n",
              " ['said'],\n",
              " ['they'],\n",
              " ['are'],\n",
              " ['really'],\n",
              " ['nice'],\n",
              " ['sturdy'],\n",
              " ['linen', 'like'],\n",
              " ['fabric'],\n",
              " ['pretty'],\n",
              " ['color'],\n",
              " ['well'],\n",
              " ['made'],\n",
              " ['hope'],\n",
              " ['they'],\n",
              " ['make'],\n",
              " ['someone'],\n",
              " ['very'],\n",
              " ['happy'],\n",
              " ['material'],\n",
              " ['and'],\n",
              " ['color'],\n",
              " ['is'],\n",
              " ['nice'],\n",
              " ['the'],\n",
              " ['leg'],\n",
              " ['opening'],\n",
              " ['is'],\n",
              " ['very'],\n",
              " ['large'],\n",
              " ['am'],\n",
              " ['and'],\n",
              " ['the'],\n",
              " ['length'],\n",
              " ['hits'],\n",
              " ['me'],\n",
              " ['right'],\n",
              " ['above'],\n",
              " ['my'],\n",
              " ['ankle'],\n",
              " ['with'],\n",
              " ['leg'],\n",
              " ['opening'],\n",
              " ['the'],\n",
              " ['size'],\n",
              " ['of'],\n",
              " ['my'],\n",
              " ['waist'],\n",
              " ['and'],\n",
              " ['hem'],\n",
              " ['line'],\n",
              " ['above'],\n",
              " ['my'],\n",
              " ['ankle'],\n",
              " ['and'],\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Bigram and Trigram Models"
      ],
      "metadata": {
        "id": "HxrpV5PTPCsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the bigram and trigram models\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "# See trigram example\n",
        "print(trigram_mod[bigram_mod[data_words[0]]])"
      ],
      "metadata": {
        "id": "d2zwYCNpocg-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d51a9207-4d2d-47f4-8d80-136f285b3fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['absolutely']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Stopwords, Make Bigrams and Lemmatize"
      ],
      "metadata": {
        "id": "p-CRGCG_PKt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent))\n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "metadata": {
        "id": "dOzoX58KPLZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from notebook.services.config import ConfigManager\n",
        "cm = ConfigManager().update('notebook', {'LimitOutput': 1000000000})"
      ],
      "metadata": {
        "id": "HYuFuLMFtB08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stop Words\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "# print(data_words_nostops)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "# print(data_words_bigrams)\n",
        "\n",
        "# In the end, we didn't create trigrams. Should have taken the extra time.\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "# python3 -m spacy download en\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(data_lemmatized[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6flm5_fPQ6F",
        "outputId": "a2381329-7db1-4070-9277-81ec9138d424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['absolutely']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topic Modeling"
      ],
      "metadata": {
        "id": "q1ashzr1PbQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "# Human readable format of corpus (term-frequency)\n",
        "# There is nothing magical about 2500:2510, I just wanted to examine a random location\n",
        "print ([[(id2word[id], freq) for id, freq in cp] for cp in corpus[2500:2510]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNpdzC6RPcB7",
        "outputId": "f2007d48-5ab3-4a69-c576-ec37b128d380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[], [('comfortable', 1)], [('material', 1)], [], [('good', 1)], [('cut', 1)], [], [], [('sleeve', 1)], [('flatter', 1)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build LDA model\n",
        "num_topics = 10\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=num_topics,\n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "metadata": {
        "id": "tx3neBxIQR4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_lda = lda_model[corpus]"
      ],
      "metadata": {
        "id": "-DlT97j5QYfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis==3.2.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kitt3JJyQg8K",
        "outputId": "e0fddaee-6b4c-4c7c-e2b1-bca42425fb46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyLDAvis==3.2.1\n",
            "  Downloading pyLDAvis-3.2.1.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from pyLDAvis==3.2.1) (0.40.0)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.9/dist-packages (from pyLDAvis==3.2.1) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.9/dist-packages (from pyLDAvis==3.2.1) (1.10.1)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.9/dist-packages (from pyLDAvis==3.2.1) (1.2.0)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.9/dist-packages (from pyLDAvis==3.2.1) (3.1.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.9/dist-packages (from pyLDAvis==3.2.1) (2.8.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from pyLDAvis==3.2.1) (0.18.3)\n",
            "Collecting funcy\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.9/dist-packages (from pyLDAvis==3.2.1) (1.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2>=2.7.2->pyLDAvis==3.2.1) (2.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.17.0->pyLDAvis==3.2.1) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.17.0->pyLDAvis==3.2.1) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas>=0.17.0->pyLDAvis==3.2.1) (1.16.0)\n",
            "Building wheels for collected packages: pyLDAvis\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-3.2.1-py2.py3-none-any.whl size=136189 sha256=8b298b0ac0db743cd3e75425af8134ce6ab0c26b7fb18d09d56599f12934121e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/cc/56/70e7bd4fdf983a26b148dffa850bfb42707601f27d915f5485\n",
            "Successfully built pyLDAvis\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-2.0 pyLDAvis-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim  # don't skip this"
      ],
      "metadata": {
        "id": "N5jS1mA3Qkmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ([itm for itm in dir(doc_lda) if not itm.startswith('__')])\n",
        "print ([itm for itm in dir(doc_lda.obj) if (not itm.startswith('__')) and (not itm.startswith('_'))])\n",
        "doc_lda.obj.print_topics(num_topics=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X40CFYiEQnZq",
        "outputId": "7a80a564-ee04-4d36-859e-018c7ebc63a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['_adapt_by_suffix', '_load_specials', '_save_specials', '_smart_save', 'add_lifecycle_event', 'chunksize', 'corpus', 'load', 'metadata', 'obj', 'save', 'save_corpus']\n",
            "['add_lifecycle_event', 'alpha', 'bound', 'callbacks', 'chunksize', 'clear', 'decay', 'diff', 'dispatcher', 'distributed', 'do_estep', 'do_mstep', 'dtype', 'eta', 'eval_every', 'expElogbeta', 'gamma_threshold', 'get_document_topics', 'get_term_topics', 'get_topic_terms', 'get_topics', 'id2word', 'inference', 'init_dir_prior', 'iterations', 'lifecycle_events', 'load', 'log_perplexity', 'minimum_phi_value', 'minimum_probability', 'num_terms', 'num_topics', 'num_updates', 'numworkers', 'offset', 'optimize_alpha', 'optimize_eta', 'passes', 'per_word_topics', 'print_topic', 'print_topics', 'random_state', 'save', 'show_topic', 'show_topics', 'state', 'sync_state', 'top_topics', 'update', 'update_alpha', 'update_eta', 'update_every']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.444*\"color\" + 0.181*\"skirt\" + 0.154*\"cut\" + 0.107*\"high\" + 0.044*\"end\" + 0.014*\"week\" + 0.000*\"wise\" + 0.000*\"pattern\" + 0.000*\"rise\" + 0.000*\"waiste\"'),\n",
              " (1,\n",
              "  '0.333*\"order\" + 0.320*\"buy\" + 0.156*\"pretty\" + 0.124*\"usually\" + 0.000*\"adn\" + 0.000*\"hunt\" + 0.000*\"sheath\" + 0.000*\"deliver\" + 0.000*\"defiantly\" + 0.000*\"nightgown\"'),\n",
              " (2,\n",
              "  '0.329*\"look\" + 0.115*\"material\" + 0.112*\"sleeve\" + 0.110*\"petite\" + 0.097*\"short\" + 0.096*\"find\" + 0.054*\"online\" + 0.049*\"thin\" + 0.008*\"waiste\" + 0.000*\"adn\"'),\n",
              " (3,\n",
              "  '0.465*\"size\" + 0.399*\"love\" + 0.103*\"shirt\" + 0.000*\"adn\" + 0.000*\"deliver\" + 0.000*\"platinum\" + 0.000*\"crosswrap\" + 0.000*\"slinky\" + 0.000*\"nightgown\" + 0.000*\"defiantly\"'),\n",
              " (4,\n",
              "  '0.046*\"dress\" + 0.017*\"great\" + 0.014*\"get\" + 0.013*\"try\" + 0.012*\"feel\" + 0.012*\"flatter\" + 0.012*\"perfect\" + 0.010*\"think\" + 0.008*\"see\" + 0.008*\"waist\"'),\n",
              " (5,\n",
              "  '0.408*\"top\" + 0.264*\"small\" + 0.140*\"large\" + 0.129*\"cute\" + 0.020*\"extra\" + 0.000*\"bulkier\" + 0.000*\"me\" + 0.000*\"red\" + 0.000*\"cheste\" + 0.000*\"adn\"'),\n",
              " (6,\n",
              "  '0.469*\"wear\" + 0.150*\"work\" + 0.142*\"much\" + 0.136*\"back\" + 0.058*\"definitely\" + 0.003*\"ready\" + 0.000*\"pre\" + 0.000*\"travel\" + 0.000*\"adn\" + 0.000*\"crosswrap\"'),\n",
              " (7,\n",
              "  '0.294*\"little\" + 0.218*\"length\" + 0.163*\"want\" + 0.140*\"store\" + 0.056*\"absolutely\" + 0.047*\"hope\" + 0.020*\"ankle\" + 0.005*\"somewhere\" + 0.000*\"tea\" + 0.000*\"normal\"'),\n",
              " (8,\n",
              "  '0.527*\"fit\" + 0.138*\"comfortable\" + 0.072*\"say\" + 0.071*\"design\" + 0.067*\"line\" + 0.043*\"knee\" + 0.040*\"never\" + 0.000*\"aesthetic\" + 0.000*\"adn\" + 0.000*\"slinky\"'),\n",
              " (9,\n",
              "  '0.214*\"fabric\" + 0.183*\"make\" + 0.161*\"go\" + 0.114*\"run\" + 0.109*\"long\" + 0.076*\"true\" + 0.074*\"retailer\" + 0.021*\"beautifully\" + 0.012*\"throw\" + 0.000*\"maxi\"')]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
        "vis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "VHoaIVEFQx4Y",
        "outputId": "f98c8561-0089-4612-efd7-0abfcea7081b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.9/dist-packages/pyLDAvis/_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  default_term_info = default_term_info.sort_values(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "4     -0.456808 -0.014061       1        1  67.231161\n",
              "2      0.064462 -0.446003       2        1   4.681650\n",
              "9      0.061293  0.056617       3        1   4.585252\n",
              "3      0.059896  0.038471       4        1   4.540818\n",
              "5      0.056150  0.060493       5        1   3.948153\n",
              "6      0.053171  0.062134       6        1   3.832435\n",
              "8      0.054443  0.062105       7        1   3.739021\n",
              "0      0.039852  0.061100       8        1   2.556456\n",
              "1      0.028726  0.058304       9        1   2.510651\n",
              "7      0.038814  0.060839      10        1   2.374401, topic_info=           Term          Freq         Total Category  logprob  loglift\n",
              "35         size  12050.000000  12050.000000  Default  30.0000  30.0000\n",
              "44          fit  11253.000000  11253.000000  Default  29.0000  29.0000\n",
              "64         wear  10254.000000  10254.000000  Default  28.0000  28.0000\n",
              "5          love  10354.000000  10354.000000  Default  27.0000  27.0000\n",
              "42          top   9190.000000   9190.000000  Default  26.0000  26.0000\n",
              "...         ...           ...           ...      ...      ...      ...\n",
              "4994  defiantly      0.089994      1.628377  Topic10 -11.9226   0.8448\n",
              "8615  crosswrap      0.089994      2.019398  Topic10 -11.9226   0.6296\n",
              "8622   platinum      0.089994      1.099134  Topic10 -11.9226   1.2379\n",
              "208        stat      0.089994      1.067591  Topic10 -11.9226   1.2670\n",
              "567     keyhole      0.089994      1.064648  Topic10 -11.9226   1.2698\n",
              "\n",
              "[589 rows x 6 columns], token_table=      Topic      Freq        Term\n",
              "term                             \n",
              "0        10  0.998195  absolutely\n",
              "923       1  0.690581         adn\n",
              "1624      1  0.990940   aesthetic\n",
              "143       1  0.999451        also\n",
              "252      10  0.997223       ankle\n",
              "...     ...       ...         ...\n",
              "241       1  0.999517         way\n",
              "64        6  0.999870        wear\n",
              "344       8  0.995323        week\n",
              "1649      1  0.983432        wise\n",
              "31        6  0.999621        work\n",
              "\n",
              "[122 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 3, 10, 4, 6, 7, 9, 1, 2, 8])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el641140250393754304766351456\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el641140250393754304766351456_data = {\"mdsDat\": {\"x\": [-0.4568079317839745, 0.06446221423362661, 0.061292749736661455, 0.05989602197956247, 0.05615015046337808, 0.053171378812399646, 0.0544432827588647, 0.03985201149531127, 0.028726300386058005, 0.03881382191811255], \"y\": [-0.01406056658121925, -0.4460034361626563, 0.0566173658556044, 0.03847101599191756, 0.06049349601829646, 0.06213448716299388, 0.06210500669458316, 0.061099800347043424, 0.058303558396121745, 0.060839272277314844], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [67.23116137991629, 4.681650067948713, 4.585252075054962, 4.540817880596741, 3.9481534248123, 3.8324354554415145, 3.7390214951000615, 2.5564557327155053, 2.5106511626723877, 2.374401325741517]}, \"tinfo\": {\"Term\": [\"size\", \"fit\", \"wear\", \"love\", \"top\", \"look\", \"color\", \"small\", \"order\", \"fabric\", \"buy\", \"little\", \"make\", \"go\", \"length\", \"work\", \"large\", \"much\", \"skirt\", \"back\", \"comfortable\", \"cute\", \"material\", \"run\", \"sleeve\", \"petite\", \"long\", \"want\", \"pretty\", \"cut\", \"dress\", \"great\", \"get\", \"try\", \"feel\", \"flatter\", \"perfect\", \"think\", \"see\", \"waist\", \"beautiful\", \"bit\", \"good\", \"really\", \"sweater\", \"soft\", \"tight\", \"nice\", \"bottom\", \"way\", \"also\", \"shoulder\", \"sale\", \"purchase\", \"light\", \"still\", \"summer\", \"jean\", \"black\", \"pant\", \"look\", \"material\", \"sleeve\", \"petite\", \"short\", \"find\", \"online\", \"thin\", \"waiste\", \"sized\", \"outrageously\", \"directly\", \"ade\", \"mintue\", \"mathce\", \"everythie\", \"prefectly\", \"msallet\", \"jkeep\", \"matvehd\", \"ejan\", \"waas\", \"compaint\", \"ldecide\", \"esp\", \"reliant\", \"estimation\", \"grrrrrrrrrrr\", \"nightwear\", \"gathering\", \"definitive\", \"adventure\", \"honolulu\", \"earth\", \"ruching\", \"disgusting\", \"thoroughly\", \"haphazardly\", \"jaggedly\", \"doo\", \"comb\", \"spoiler\", \"traverse\", \"secret\", \"unseame\", \"spendy\", \"grippie\", \"worker\", \"update\", \"shelf\", \"adn\", \"crosswrap\", \"slinky\", \"nightgown\", \"defiantly\", \"deliver\", \"sheath\", \"platinum\", \"hunt\", \"honey\", \"camel\", \"object\", \"differ\", \"regardless\", \"confident\", \"win\", \"falttere\", \"precious\", \"chemise\", \"picnic\", \"ribbon\", \"fabric\", \"make\", \"go\", \"run\", \"long\", \"true\", \"retailer\", \"beautifully\", \"throw\", \"maxi\", \"limn\", \"loser\", \"outrageously\", \"directly\", \"ade\", \"mintue\", \"mathce\", \"everythie\", \"prefectly\", \"msallet\", \"jkeep\", \"matvehd\", \"ejan\", \"waas\", \"compaint\", \"ldecide\", \"esp\", \"reliant\", \"estimation\", \"grrrrrrrrrrr\", \"torsoe\", \"grip\", \"silicon\", \"sid\", \"sensitivity\", \"blister\", \"silicone\", \"causal\", \"cash\", \"perc\", \"gateway\", \"stature\", \"cappier\", \"flatten\", \"ope\", \"backward\", \"unwanted\", \"chair\", \"delicacy\", \"rooftop\", \"improve\", \"conference\", \"footless\", \"coal\", \"skintone\", \"sallow\", \"instant\", \"glamour\", \"par\", \"mound\", \"thorwback\", \"fragile\", \"eggplant\", \"adn\", \"slinky\", \"crosswrap\", \"nightgown\", \"defiantly\", \"deliver\", \"platinum\", \"sheath\", \"hunt\", \"honey\", \"object\", \"differ\", \"camel\", \"regardless\", \"confident\", \"precious\", \"win\", \"falttere\", \"chemise\", \"size\", \"love\", \"shirt\", \"outrageously\", \"directly\", \"ade\", \"mintue\", \"mathce\", \"everythie\", \"prefectly\", \"msallet\", \"jkeep\", \"matvehd\", \"ejan\", \"waas\", \"compaint\", \"ldecide\", \"esp\", \"reliant\", \"estimation\", \"grrrrrrrrrrr\", \"nightwear\", \"gathering\", \"whit\", \"cry\", \"squat\", \"redo\", \"tigh\", \"kiss\", \"underrate\", \"adn\", \"deliver\", \"platinum\", \"crosswrap\", \"slinky\", \"nightgown\", \"defiantly\", \"sheath\", \"hunt\", \"honey\", \"camel\", \"differ\", \"object\", \"regardless\", \"confident\", \"win\", \"chemise\", \"falttere\", \"precious\", \"picnic\", \"ribbon\", \"puffy\", \"theory\", \"batch\", \"coverup\", \"pain\", \"numerous\", \"top\", \"small\", \"large\", \"cute\", \"extra\", \"bulkier\", \"me\", \"red\", \"outrageously\", \"directly\", \"ade\", \"mintue\", \"mathce\", \"everythie\", \"prefectly\", \"msallet\", \"jkeep\", \"matvehd\", \"ejan\", \"waas\", \"compaint\", \"ldecide\", \"esp\", \"reliant\", \"estimation\", \"grrrrrrrrrrr\", \"nightwear\", \"gathering\", \"whit\", \"cry\", \"cheste\", \"adn\", \"deliver\", \"platinum\", \"crosswrap\", \"slinky\", \"defiantly\", \"nightgown\", \"sheath\", \"comfy\", \"hunt\", \"honey\", \"camel\", \"object\", \"differ\", \"regardless\", \"confident\", \"win\", \"chemise\", \"falttere\", \"precious\", \"picnic\", \"wear\", \"work\", \"much\", \"back\", \"definitely\", \"ready\", \"outrageously\", \"directly\", \"ade\", \"mintue\", \"mathce\", \"everythie\", \"prefectly\", \"msallet\", \"jkeep\", \"matvehd\", \"ejan\", \"waas\", \"compaint\", \"ldecide\", \"esp\", \"reliant\", \"estimation\", \"grrrrrrrrrrr\", \"nightwear\", \"gathering\", \"whit\", \"cry\", \"squat\", \"redo\", \"pre\", \"travel\", \"adn\", \"crosswrap\", \"slinky\", \"deliver\", \"nightgown\", \"platinum\", \"defiantly\", \"sheath\", \"hunt\", \"honey\", \"differ\", \"camel\", \"object\", \"regardless\", \"confident\", \"picnic\", \"win\", \"precious\", \"ribbon\", \"chemise\", \"falttere\", \"puffy\", \"fit\", \"comfortable\", \"say\", \"design\", \"line\", \"knee\", \"never\", \"tulip\", \"outrageously\", \"directly\", \"ade\", \"mintue\", \"mathce\", \"everythie\", \"prefectly\", \"msallet\", \"jkeep\", \"matvehd\", \"ejan\", \"waas\", \"compaint\", \"ldecide\", \"esp\", \"reliant\", \"estimation\", \"grrrrrrrrrrr\", \"nightwear\", \"gathering\", \"whit\", \"cry\", \"aesthetic\", \"adn\", \"slinky\", \"crosswrap\", \"nightgown\", \"defiantly\", \"sheath\", \"deliver\", \"platinum\", \"hunt\", \"honey\", \"differ\", \"camel\", \"object\", \"regardless\", \"confident\", \"win\", \"picnic\", \"precious\", \"falttere\", \"ribbon\", \"chemise\", \"theory\", \"color\", \"skirt\", \"cut\", \"high\", \"end\", \"week\", \"maintenance\", \"outrageously\", \"directly\", \"ade\", \"mintue\", \"mathce\", \"everythie\", \"prefectly\", \"msallet\", \"jkeep\", \"matvehd\", \"ejan\", \"waas\", \"compaint\", \"ldecide\", \"esp\", \"reliant\", \"estimation\", \"grrrrrrrrrrr\", \"nightwear\", \"gathering\", \"whit\", \"cry\", \"squat\", \"wise\", \"pattern\", \"rise\", \"waiste\", \"feel\", \"skin\", \"knee\", \"fit\", \"adn\", \"short\", \"low\", \"slinky\", \"nightgown\", \"crosswrap\", \"hunt\", \"sheath\", \"deliver\", \"camel\", \"defiantly\", \"platinum\", \"style\", \"differ\", \"honey\", \"order\", \"buy\", \"pretty\", \"usually\", \"outrageously\", \"directly\", \"ade\", \"mintue\", \"mathce\", \"everythie\", \"prefectly\", \"msallet\", \"jkeep\", \"matvehd\", \"ejan\", \"waas\", \"compaint\", \"ldecide\", \"esp\", \"reliant\", \"estimation\", \"grrrrrrrrrrr\", \"nightwear\", \"gathering\", \"whit\", \"cry\", \"squat\", \"redo\", \"tigh\", \"kiss\", \"adn\", \"slinky\", \"hunt\", \"nightgown\", \"sheath\", \"deliver\", \"defiantly\", \"crosswrap\", \"platinum\", \"differ\", \"confident\", \"win\", \"chemise\", \"camel\", \"regardless\", \"honey\", \"object\", \"stat\", \"numerous\", \"obvious\", \"puffy\", \"ribbon\", \"batch\", \"retain\", \"count\", \"picnic\", \"little\", \"length\", \"want\", \"store\", \"absolutely\", \"hope\", \"ankle\", \"somewhere\", \"tea\", \"outrageously\", \"directly\", \"ade\", \"mintue\", \"mathce\", \"everythie\", \"prefectly\", \"msallet\", \"jkeep\", \"matvehd\", \"ejan\", \"waas\", \"compaint\", \"ldecide\", \"esp\", \"reliant\", \"estimation\", \"grrrrrrrrrrr\", \"nightwear\", \"gathering\", \"whit\", \"normal\", \"half\", \"elbow\", \"arm\", \"full\", \"give\", \"adn\", \"slinky\", \"differ\", \"hunt\", \"nightgown\", \"sheath\", \"deliver\", \"camel\", \"honey\", \"object\", \"defiantly\", \"crosswrap\", \"platinum\", \"stat\", \"keyhole\"], \"Freq\": [12050.0, 11253.0, 10254.0, 10354.0, 9190.0, 8800.0, 6476.0, 5942.0, 4767.0, 5598.0, 4586.0, 3989.0, 4793.0, 4217.0, 2954.0, 3285.0, 3155.0, 3102.0, 2644.0, 2973.0, 2947.0, 2915.0, 3062.0, 2984.0, 2993.0, 2930.0, 2863.0, 2212.0, 2238.0, 2248.0, 17709.57670407395, 6558.525832848567, 5406.305205917837, 5071.967698614967, 4645.560618571151, 4501.904743997812, 4435.272616211018, 3826.6207483666008, 3256.225324860298, 3246.9247758064407, 3232.591791749849, 3140.325597622849, 3132.273058130301, 3054.6841142322037, 3025.4797610146575, 2955.7131308407083, 2912.235494969246, 2835.8859807901567, 2543.6054304711406, 2534.311316299009, 2519.471406559823, 2321.4386364458182, 2239.584259697318, 2220.7284475213046, 2096.5643659345114, 2057.765782811027, 2057.5316246149064, 2048.3106178490443, 2035.678230035119, 2013.339716871918, 8799.705257487054, 3061.5052794837998, 2992.4175847892648, 2930.038550844785, 2591.4427679471596, 2574.920654512912, 1451.8292868275303, 1315.386626253275, 216.55500540939363, 0.09244877995342138, 0.09240960335250828, 0.09240960335250828, 0.09240960335250828, 0.09240960335250828, 0.09240960335250828, 0.09240960335250828, 0.09240960335250828, 0.09240960335250828, 0.09240960335250828, 0.09240960335250828, 0.09240960335250828, 0.09240960335250828, 0.09240960335250828, 0.09240960335250828, 0.09240960335250828, 0.09240960335250828, 0.09240960335250828, 0.09240960335250828, 0.09240960335250828, 0.09240960335250828, 0.09242344218593662, 0.09242584286191563, 0.09242584286191563, 0.09242327201143684, 0.09242351511786509, 0.09242315045822272, 0.09242315045822272, 0.09242535664905913, 0.09242535664905913, 0.09242632907477213, 0.09242521686286287, 0.09242564229911232, 0.09242564229911232, 0.09242688821955712, 0.09242688821955712, 0.09242688821955712, 0.09242293166243729, 0.09242970825412486, 0.09242454832018518, 0.09242454832018518, 0.09249549893127104, 0.09248077883704027, 0.09248071198277251, 0.0924785057919361, 0.09247847540363258, 0.09247800134609747, 0.09247780686095487, 0.09247736926938402, 0.09247575868929683, 0.09247338840162136, 0.09247039819255384, 0.09246972357221543, 0.09246926774766245, 0.09246477027873977, 0.09246288620392079, 0.09246031535344201, 0.0924601938002279, 0.09245936116071111, 0.09245909374364004, 0.09245889318083673, 0.0924574284646065, 5597.8867261455025, 4792.290692428761, 4216.227300846546, 2983.649519325451, 2862.094409559665, 1978.181832729123, 1943.997780088749, 549.785288602029, 322.2001198811444, 0.27241665357495976, 0.11259429495929713, 0.1083070890999191, 0.1083065414682618, 0.1083065414682618, 0.1083065414682618, 0.1083065414682618, 0.1083065414682618, 0.1083065414682618, 0.1083065414682618, 0.1083065414682618, 0.1083065414682618, 0.1083065414682618, 0.1083065414682618, 0.1083065414682618, 0.1083065414682618, 0.1083065414682618, 0.1083065414682618, 0.1083065414682618, 0.1083065414682618, 0.1083065414682618, 0.10830873199489098, 0.10830655337329782, 0.10830655337329782, 0.10830655337329782, 0.10830655337329782, 0.10830655337329782, 0.10830655337329782, 0.10830655337329782, 0.10830655337329782, 0.10830655337329782, 0.10830655337329782, 0.10830655337329782, 0.10830655337329782, 0.10830655337329782, 0.10830655337329782, 0.10830655337329782, 0.10830655337329782, 0.10830655337329782, 0.10830656527833385, 0.10830656527833385, 0.10830656527833385, 0.10830656527833385, 0.10830656527833385, 0.10830656527833385, 0.10830656527833385, 0.10830656527833385, 0.10830656527833385, 0.10830656527833385, 0.10830656527833385, 0.10830656527833385, 0.10830656527833385, 0.10830656527833385, 0.10830656527833385, 0.1084034603665676, 0.10838809096505517, 0.10838805524994707, 0.10838661474058767, 0.10838557900245321, 0.10838479327007534, 0.10838412658805777, 0.10838338847582402, 0.10838159081538375, 0.10837913837796194, 0.10837749548299004, 0.10837723357219742, 0.10837643593478352, 0.10837040008151722, 0.10836797145416746, 0.10836476899947586, 0.10836381659659361, 0.10836284038363929, 0.10836249513759447, 12049.717388827392, 10353.20943956005, 2664.136185716815, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09961581091715392, 0.09968829379709718, 0.099677199719344, 0.09967658665659887, 0.09967652770825798, 0.09967631549423082, 0.09967611506987184, 0.0996753133724359, 0.09967499505139517, 0.09967290828012809, 0.09967157604762425, 0.09966861684091219, 0.0996670723943812, 0.09966687197002222, 0.09966236831677916, 0.09966096534626627, 0.09966024617650755, 0.09965995143480316, 0.09965852488495393, 0.09965840698827218, 0.09965767602884529, 0.09965657958970496, 0.09965547136089646, 0.0996543867114243, 0.09965406839038357, 0.09965390333502912, 0.09965303089958412, 0.09965297195124324, 9189.824731508515, 5941.738815414867, 3154.194498703654, 2915.0503670356516, 453.90977757723357, 0.1368485238182549, 0.10469842576018139, 0.10300530697233463, 0.10294608758820824, 0.10294608758820824, 0.10294608758820824, 0.10294608758820824, 0.10294608758820824, 0.10294608758820824, 0.10294608758820824, 0.10294608758820824, 0.10294608758820824, 0.10294608758820824, 0.10294608758820824, 0.10294608758820824, 0.10294608758820824, 0.10294608758820824, 0.10294608758820824, 0.10294608758820824, 0.10294608758820824, 0.10294608758820824, 0.10294608758820824, 0.10294608758820824, 0.10294608758820824, 0.10294608758820824, 0.10297961824520624, 0.10296811674806415, 0.10296453918790142, 0.1029643649227932, 0.10296418040679628, 0.10296414965413012, 0.10296399589079934, 0.10296384212746856, 0.10296382162569112, 0.10296352434991829, 0.10296339108836496, 0.10296262227171107, 0.10296177144794744, 0.10296133065973255, 0.10296123840173409, 0.10296016205841864, 0.10295977252464734, 0.10295963926309401, 0.10295921897665655, 0.10295918822399039, 0.1029587986902191, 0.1029586346759996, 10253.41919637959, 3284.3333924618946, 3101.704173849578, 2972.390664732849, 1270.4686517328335, 66.22414681732845, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10824087192523062, 0.10860175453468383, 0.10832673428425157, 0.10825930014274213, 0.10825682248282832, 0.10825678268106263, 0.1082564344156129, 0.10825639461384723, 0.108256295109433, 0.1082561956050188, 0.10825596674486612, 0.10825588714133476, 0.10825510105646251, 0.10825451398041867, 0.10825445427777014, 0.10825429507070741, 0.10825295176111559, 0.10825254379301734, 0.10825206617182913, 0.10825198656829776, 0.10825197661785635, 0.10825177760902792, 0.1082516681541723, 0.10825160845152378, 0.10825087211885863, 11252.388938585285, 2946.536789182471, 1534.1564461584774, 1506.3874750236894, 1435.3283784982814, 926.4168269391348, 854.7775003480882, 0.10351869731345166, 0.10351868760554794, 0.10351868760554794, 0.10351868760554794, 0.10351868760554794, 0.10351868760554794, 0.10351868760554794, 0.10351868760554794, 0.10351868760554794, 0.10351868760554794, 0.10351868760554794, 0.10351868760554794, 0.10351868760554794, 0.10351868760554794, 0.10351868760554794, 0.10351868760554794, 0.10351868760554794, 0.10351868760554794, 0.10351868760554794, 0.10351868760554794, 0.10351868760554794, 0.10351868760554794, 0.10351868760554794, 0.10519218458579854, 0.10353228837863918, 0.103530152639824, 0.10353007497659435, 0.10352972549206096, 0.10352968666044614, 0.1035296089972165, 0.10352941483914238, 0.10352931776010534, 0.10352922068106828, 0.1035289100281497, 0.10352842463296444, 0.1035283663855422, 0.10352829843021627, 0.10352740530307537, 0.10352714318967533, 0.10352679370514194, 0.10352677428933453, 0.10352668691820117, 0.10352663837868264, 0.10352646363641595, 0.10352640538899371, 0.10352593940961587, 6475.200449095739, 2643.5775646638212, 2247.628360035543, 1555.3258663341162, 649.4700252136242, 211.0664047872703, 0.09444019954823508, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.09444005352281787, 0.0945063225121537, 0.09445470916469022, 0.09445155634318235, 0.0944461932278595, 0.09444517768745803, 0.09444428162239789, 0.09444044513643675, 0.09444020618575405, 0.09444014644808336, 0.0944401398105644, 0.09444013317304543, 0.09444013317304543, 0.09444013317304543, 0.09444013317304543, 0.09444011989800752, 0.09444011989800752, 0.09444011989800752, 0.09444011989800752, 0.09444011989800752, 0.09444011989800752, 0.09444011326048855, 0.09444011326048855, 0.09444011326048855, 4767.0584811590315, 4585.096695255044, 2237.326655005121, 1773.0268320781415, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277724057481431, 0.11277733183511773, 0.11277731879793153, 0.11277731879793153, 0.11277731879793153, 0.11277731879793153, 0.11277731879793153, 0.11277731879793153, 0.11277731879793153, 0.11277731879793153, 0.11277730576074532, 0.11277730576074532, 0.11277730576074532, 0.11277730576074532, 0.11277730576074532, 0.11277730576074532, 0.11277730576074532, 0.11277730576074532, 0.11277729272355913, 0.11277729272355913, 0.11277729272355913, 0.11277729272355913, 0.11277729272355913, 0.11277729272355913, 0.11277729272355913, 0.11277729272355913, 0.11277729272355913, 3988.2027200590824, 2954.023522046434, 2211.4489198916735, 1893.957022607694, 759.4431943270318, 637.9115166693289, 265.8112287985339, 70.51752021893603, 0.09060865891295847, 0.08999442534191879, 0.08999442534191879, 0.08999442534191879, 0.08999442534191879, 0.08999442534191879, 0.08999442534191879, 0.08999442534191879, 0.08999442534191879, 0.08999442534191879, 0.08999442534191879, 0.08999442534191879, 0.08999442534191879, 0.08999442534191879, 0.08999442534191879, 0.08999442534191879, 0.08999442534191879, 0.08999442534191879, 0.08999442534191879, 0.08999442534191879, 0.08999442534191879, 0.08999442534191879, 0.0900229315499028, 0.09001402952474517, 0.08999579393581422, 0.08999485688053446, 0.08999477057281133, 0.0899946657705761, 0.08999445616610563, 0.08999445000126827, 0.08999445000126827, 0.08999445000126827, 0.08999445000126827, 0.08999445000126827, 0.08999445000126827, 0.08999445000126827, 0.08999445000126827, 0.08999445000126827, 0.08999445000126827, 0.08999445000126827, 0.08999445000126827, 0.08999444383643089, 0.08999444383643089], \"Total\": [12050.0, 11253.0, 10254.0, 10354.0, 9190.0, 8800.0, 6476.0, 5942.0, 4767.0, 5598.0, 4586.0, 3989.0, 4793.0, 4217.0, 2954.0, 3285.0, 3155.0, 3102.0, 2644.0, 2973.0, 2947.0, 2915.0, 3062.0, 2984.0, 2993.0, 2930.0, 2863.0, 2212.0, 2238.0, 2248.0, 17710.488953474756, 6559.438083075567, 5407.217455287887, 5072.879947985017, 4646.4728746903265, 4502.816993367862, 4436.184865587146, 3827.5329977366523, 3257.1375742303494, 3247.837027723805, 3233.5040411199006, 3141.2378469929004, 3133.1853075003523, 3055.596363602255, 3026.3920103729192, 2956.62538021076, 2913.1477443553254, 2836.7982301602083, 2544.517679878022, 2535.2235656690605, 2520.3836559298747, 2322.3508865372487, 2240.4965090673695, 2221.640696891356, 2097.476615330842, 2058.6780321810784, 2058.443874000986, 2049.222867219096, 2036.5904794051708, 2014.2519662419697, 8800.632265429322, 3062.432288103473, 2993.3445945032063, 2930.965559289901, 2592.36977605308, 2575.8476630562163, 1452.7562950980891, 1316.3136356812713, 217.4820211288373, 1.0194583815116853, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.0341385053540946, 1.0368963698923908, 1.0368963698923908, 1.034038231275596, 1.0343171290781072, 1.033927096923465, 1.0339271732923008, 1.0364000198305157, 1.0364000307403494, 1.037510225973296, 1.0362687748045305, 1.0367562531397354, 1.0367562531397354, 1.0381953002661246, 1.0381953002661246, 1.0381953002661246, 1.0337808310370855, 1.0414139897457277, 1.0356289808030885, 1.0356289808030885, 1.448056949716384, 2.01939815727721, 1.9713018757274532, 1.9755900206072154, 1.6283768389833329, 1.150564835225039, 8.334359908640849, 1.0991340151187567, 1.6184015258807412, 267.2074835131022, 2.4283716599276883, 4.236770560172465, 1.9636131528954235, 3.6445143721447004, 1.330699235577388, 1.3770618204153517, 1.2246702328595356, 1.9644149898617926, 1.1660729534773588, 1.6373806889448697, 1.595817828871874, 5598.797837144821, 4793.201803548088, 4217.138410868813, 2984.5606295440957, 2863.005520337904, 1979.0929439630866, 1944.9088904274022, 550.6964018487752, 323.11123633538165, 1.2030331009738888, 1.0242222901408984, 1.0194140893435604, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019751051462206, 1.0194176181527195, 1.0194176181527195, 1.0194176181527195, 1.0194176508822204, 1.0194176508822204, 1.0194176727018875, 1.019417694521555, 1.019417694521555, 1.0194178254395587, 1.0194178254395587, 1.0194178908985607, 1.0194179018083944, 1.0194179345378953, 1.0194179672673964, 1.0194179672673964, 1.0194180218165645, 1.0194181527345685, 1.019426887674355, 1.019426887674355, 1.0194272476988657, 1.019427487715206, 1.019427487715206, 1.01942761863321, 1.019428436870734, 1.019428436870734, 1.019428535059237, 1.019428535059237, 1.019428687796908, 1.019428687796908, 1.019428687796908, 1.0194286987067418, 1.0194287096165755, 1.448056949716384, 1.9713018757274532, 2.01939815727721, 1.9755900206072154, 1.6283768389833329, 1.150564835225039, 1.0991340151187567, 8.334359908640849, 1.6184015258807412, 267.2074835131022, 4.236770560172465, 1.9636131528954235, 2.4283716599276883, 3.6445143721447004, 1.330699235577388, 1.9644149898617926, 1.3770618204153517, 1.2246702328595356, 1.1660729534773588, 12050.637190381603, 10354.12924086927, 2665.0559894005423, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.448056949716384, 1.150564835225039, 1.0991340151187567, 2.01939815727721, 1.9713018757274532, 1.9755900206072154, 1.6283768389833329, 8.334359908640849, 1.6184015258807412, 267.2074835131022, 2.4283716599276883, 1.9636131528954235, 4.236770560172465, 3.6445143721447004, 1.330699235577388, 1.3770618204153517, 1.1660729534773588, 1.2246702328595356, 1.9644149898617926, 1.6373806889448697, 1.595817828871874, 1.1316609835152154, 1.44500479808489, 1.175174008316495, 1.093552205302438, 28.201172234576678, 1.2213698798199877, 9190.741202717985, 5942.655285738275, 3155.1109688743263, 2915.96683860886, 454.8262482279385, 1.0567272614040053, 1.021373706810052, 1.0194800886672748, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 27.30735215888261, 1.448056949716384, 1.150564835225039, 1.0991340151187567, 2.01939815727721, 1.9713018757274532, 1.6283768389833329, 1.9755900206072154, 8.334359908640849, 1092.4069149104569, 1.6184015258807412, 267.2074835131022, 2.4283716599276883, 4.236770560172465, 1.9636131528954235, 3.6445143721447004, 1.330699235577388, 1.3770618204153517, 1.1660729534773588, 1.2246702328595356, 1.9644149898617926, 1.6373806889448697, 10254.330372235047, 3285.244568295533, 3102.6153492904627, 2973.301840326471, 1271.3798274464639, 67.13532107995083, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.0230904056694847, 154.21992915753776, 1.448056949716384, 2.01939815727721, 1.9713018757274532, 1.150564835225039, 1.9755900206072154, 1.0991340151187567, 1.6283768389833329, 8.334359908640849, 1.6184015258807412, 267.2074835131022, 1.9636131528954235, 2.4283716599276883, 4.236770560172465, 3.6445143721447004, 1.330699235577388, 1.6373806889448697, 1.3770618204153517, 1.9644149898617926, 1.595817828871874, 1.1660729534773588, 1.2246702328595356, 1.1316609835152154, 11253.304836646807, 2947.452687320437, 1535.0723440455176, 1507.3033731398361, 1436.244276559879, 927.3327257960098, 855.6933999441353, 1.0194134641411376, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 78.7131739058289, 1.448056949716384, 1.9713018757274532, 2.01939815727721, 1.9755900206072154, 1.6283768389833329, 8.334359908640849, 1.150564835225039, 1.0991340151187567, 1.6184015258807412, 267.2074835131022, 1.9636131528954235, 2.4283716599276883, 4.236770560172465, 3.6445143721447004, 1.330699235577388, 1.3770618204153517, 1.6373806889448697, 1.9644149898617926, 1.2246702328595356, 1.595817828871874, 1.1660729534773588, 1.44500479808489, 6476.125424995001, 2644.502540873541, 2248.553336632388, 1556.2508425427802, 650.3950011019767, 211.99138170114716, 1.0194135349996492, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 36.60650127591149, 1597.7360290587558, 267.9427821840192, 217.4820211288373, 4646.4728746903265, 511.04416070475554, 927.3327257960098, 11253.304836646807, 1.448056949716384, 2592.36977605308, 516.1389741563571, 1.9713018757274532, 1.9755900206072154, 2.01939815727721, 1.6184015258807412, 8.334359908640849, 1.150564835225039, 2.4283716599276883, 1.6283768389833329, 1.0991340151187567, 1993.3882922806379, 1.9636131528954235, 267.2074835131022, 4767.965119347569, 4586.003333476312, 2238.2332935427744, 1773.9334701794012, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.448056949716384, 1.9713018757274532, 1.6184015258807412, 1.9755900206072154, 8.334359908640849, 1.150564835225039, 1.6283768389833329, 2.01939815727721, 1.0991340151187567, 1.9636131528954235, 1.330699235577388, 1.3770618204153517, 1.1660729534773588, 2.4283716599276883, 3.6445143721447004, 267.2074835131022, 4.236770560172465, 1.0675909155841654, 1.2213698798199877, 5.026266800218673, 1.1316609835152154, 1.595817828871874, 1.175174008316495, 1.067251510416514, 1.0773146512084502, 1.6373806889448697, 3989.1321417174436, 2954.9529435084182, 2212.378341604584, 1894.8864441351373, 760.3726160290324, 638.8409377276492, 266.74064904952655, 71.90698056777681, 1.0200776529145748, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 1.019413388974232, 597.4695173976133, 785.1978880742289, 50.50551557534336, 1150.9312534486417, 670.4480638118386, 1317.2037708819826, 1.448056949716384, 1.9713018757274532, 1.9636131528954235, 1.6184015258807412, 1.9755900206072154, 8.334359908640849, 1.150564835225039, 2.4283716599276883, 267.2074835131022, 4.236770560172465, 1.6283768389833329, 2.01939815727721, 1.0991340151187567, 1.0675909155841654, 1.0646482949917628], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.0762, -4.0695, -4.2627, -4.3265, -4.4144, -4.4458, -4.4607, -4.6083, -4.7697, -4.7726, -4.777, -4.8059, -4.8085, -4.8336, -4.8432, -4.8665, -4.8813, -4.9079, -5.0167, -5.0203, -5.0262, -5.1081, -5.144, -5.1524, -5.21, -5.2286, -5.2288, -5.2333, -5.2394, -5.2505, -1.1111, -2.1669, -2.1897, -2.2108, -2.3336, -2.34, -2.913, -3.0116, -4.8157, -12.5746, -12.5751, -12.5751, -12.5751, -12.5751, -12.5751, -12.5751, -12.5751, -12.5751, -12.5751, -12.5751, -12.5751, -12.5751, -12.5751, -12.5751, -12.5751, -12.5751, -12.5751, -12.5751, -12.5751, -12.5751, -12.5749, -12.5749, -12.5749, -12.5749, -12.5749, -12.5749, -12.5749, -12.5749, -12.5749, -12.5749, -12.5749, -12.5749, -12.5749, -12.5749, -12.5749, -12.5749, -12.5749, -12.5748, -12.5749, -12.5749, -12.5741, -12.5743, -12.5743, -12.5743, -12.5743, -12.5743, -12.5743, -12.5743, -12.5743, -12.5744, -12.5744, -12.5744, -12.5744, -12.5745, -12.5745, -12.5745, -12.5745, -12.5745, -12.5745, -12.5745, -12.5745, -1.5426, -1.698, -1.826, -2.1718, -2.2134, -2.5828, -2.6002, -3.8632, -4.3976, -11.4732, -12.3567, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3955, -12.3946, -12.3948, -12.3948, -12.3948, -12.3948, -12.3948, -12.3948, -12.3948, -12.3948, -12.3948, -12.3949, -12.3949, -12.3949, -12.3949, -12.395, -12.395, -12.395, -12.395, -12.395, -0.7662, -0.9179, -2.2754, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4694, -12.4687, -12.4688, -12.4688, -12.4688, -12.4688, -12.4688, -12.4688, -12.4688, -12.4689, -12.4689, -12.4689, -12.4689, -12.4689, -12.469, -12.469, -12.469, -12.469, -12.469, -12.469, -12.469, -12.469, -12.469, -12.469, -12.469, -12.469, -12.4691, -12.4691, -0.8973, -1.3334, -1.9666, -2.0455, -3.9052, -12.012, -12.2798, -12.2961, -12.2967, -12.2967, -12.2967, -12.2967, -12.2967, -12.2967, -12.2967, -12.2967, -12.2967, -12.2967, -12.2967, -12.2967, -12.2967, -12.2967, -12.2967, -12.2967, -12.2967, -12.2967, -12.2967, -12.2967, -12.2967, -12.2967, -12.2964, -12.2965, -12.2965, -12.2965, -12.2965, -12.2965, -12.2965, -12.2965, -12.2965, -12.2965, -12.2965, -12.2965, -12.2965, -12.2965, -12.2965, -12.2965, -12.2965, -12.2966, -12.2966, -12.2966, -12.2966, -12.2966, -0.758, -1.8965, -1.9537, -1.9963, -2.8462, -5.8003, -12.2168, -12.2168, -12.2168, -12.2168, -12.2168, -12.2168, -12.2168, -12.2168, -12.2168, -12.2168, -12.2168, -12.2168, -12.2168, -12.2168, -12.2168, -12.2168, -12.2168, -12.2168, -12.2168, -12.2168, -12.2168, -12.2168, -12.2168, -12.2168, -12.2135, -12.216, -12.2166, -12.2166, -12.2166, -12.2166, -12.2166, -12.2166, -12.2166, -12.2166, -12.2166, -12.2167, -12.2167, -12.2167, -12.2167, -12.2167, -12.2167, -12.2167, -12.2167, -12.2167, -12.2167, -12.2167, -12.2167, -12.2167, -0.6404, -1.9803, -2.633, -2.6512, -2.6996, -3.1374, -3.2179, -12.2367, -12.2367, -12.2367, -12.2367, -12.2367, -12.2367, -12.2367, -12.2367, -12.2367, -12.2367, -12.2367, -12.2367, -12.2367, -12.2367, -12.2367, -12.2367, -12.2367, -12.2367, -12.2367, -12.2367, -12.2367, -12.2367, -12.2367, -12.2207, -12.2366, -12.2366, -12.2366, -12.2366, -12.2366, -12.2366, -12.2366, -12.2366, -12.2366, -12.2366, -12.2366, -12.2366, -12.2366, -12.2366, -12.2366, -12.2366, -12.2366, -12.2366, -12.2366, -12.2366, -12.2366, -12.2366, -0.8128, -1.7086, -1.8709, -2.2391, -3.1124, -4.2363, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9476, -11.9481, -11.9482, -11.9482, -11.9482, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -11.9483, -1.1009, -1.1399, -1.8574, -2.09, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -11.7528, -1.2235, -1.5237, -1.8132, -1.9682, -2.882, -3.0564, -3.9318, -5.2588, -11.9158, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9223, -11.9224, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226, -11.9226], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.397, 0.3969, 0.3969, 0.3969, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3967, 0.3967, 0.3967, 0.3967, 0.3967, 0.3967, 0.3967, 0.3967, 0.3967, 0.3967, 0.3966, 0.3966, 0.3966, 0.3966, 0.3966, 0.3966, 0.3966, 0.3966, 0.3966, 3.0614, 3.0612, 3.0612, 3.0612, 3.0612, 3.0612, 3.0609, 3.0608, 3.0572, 0.6611, 0.6608, 0.6608, 0.6608, 0.6608, 0.6608, 0.6608, 0.6608, 0.6608, 0.6608, 0.6608, 0.6608, 0.6608, 0.6608, 0.6608, 0.6608, 0.6608, 0.6608, 0.6608, 0.6608, 0.6608, 0.6466, 0.6439, 0.6439, 0.6467, 0.6464, 0.6468, 0.6468, 0.6444, 0.6444, 0.6434, 0.6445, 0.6441, 0.6441, 0.6427, 0.6427, 0.6427, 0.6469, 0.6396, 0.6451, 0.6451, 0.3107, -0.022, 0.0021, -0.0001, 0.1932, 0.5405, -1.4397, 0.5862, 0.1993, -4.9073, -0.2066, -0.7632, 0.0059, -0.6126, 0.3949, 0.3606, 0.4779, 0.0053, 0.5269, 0.1874, 0.2131, 3.0822, 3.0821, 3.0821, 3.082, 3.082, 3.0819, 3.0819, 3.0807, 3.0795, 1.5971, 0.8744, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.84, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.8403, 0.4902, 0.1816, 0.1575, 0.1794, 0.3727, 0.72, 0.7657, -1.2601, 0.3788, -4.7278, -0.5836, 0.1854, -0.027, -0.4331, 0.5744, 0.1849, 0.5401, 0.6574, 0.7064, 3.092, 3.092, 3.0917, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.7664, 0.4161, 0.646, 0.6917, 0.0834, 0.1075, 0.1054, 0.2986, -1.3342, 0.3048, -4.8018, -0.1011, 0.1114, -0.6577, -0.5071, 0.5004, 0.4661, 0.6324, 0.5834, 0.1109, 0.293, 0.3187, 0.6623, 0.4179, 0.6246, 0.6966, -2.5534, 0.586, 3.2318, 3.2318, 3.2316, 3.2316, 3.2299, 1.1879, 0.9541, 0.9397, 0.9391, 0.9391, 0.9391, 0.9391, 0.9391, 0.9391, 0.9391, 0.9391, 0.9391, 0.9391, 0.9391, 0.9391, 0.9391, 0.9391, 0.9391, 0.9391, 0.9391, 0.9391, 0.9391, 0.9391, 0.9391, 0.9391, -2.3485, 0.5884, 0.8183, 0.864, 0.2557, 0.2799, 0.471, 0.2777, -1.1618, -6.0376, 0.4771, -4.6295, 0.0713, -0.4853, 0.2837, -0.3347, 0.6728, 0.6386, 0.8049, 0.7558, 0.2833, 0.4654, 3.2616, 3.2614, 3.2614, 3.2614, 3.261, 3.248, 1.019, 1.019, 1.019, 1.019, 1.019, 1.019, 1.019, 1.019, 1.019, 1.019, 1.019, 1.019, 1.019, 1.019, 1.019, 1.019, 1.019, 1.019, 1.019, 1.019, 1.019, 1.019, 1.019, 1.019, 1.0188, -3.9993, 0.6682, 0.3356, 0.3597, 0.8982, 0.3575, 0.9439, 0.5508, -1.082, 0.557, -4.5496, 0.3636, 0.1512, -0.4054, -0.2548, 0.7527, 0.5453, 0.7184, 0.3632, 0.571, 0.8847, 0.8357, 0.9147, 3.2863, 3.286, 3.2857, 3.2857, 3.2857, 3.2854, 3.2853, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, -3.3314, 0.6483, 0.3398, 0.3157, 0.3376, 0.5309, -1.1019, 0.8782, 0.9239, 0.537, -4.5696, 0.3437, 0.1312, -0.4254, -0.2748, 0.7327, 0.6985, 0.5253, 0.3432, 0.8157, 0.551, 0.8648, 0.6503, 3.6664, 3.6662, 3.6661, 3.666, 3.6651, 3.6622, 1.2875, 1.2875, 1.2875, 1.2875, 1.2875, 1.2875, 1.2875, 1.2875, 1.2875, 1.2875, 1.2875, 1.2875, 1.2875, 1.2875, 1.2875, 1.2875, 1.2875, 1.2875, 1.2875, 1.2875, 1.2875, 1.2875, 1.2875, 1.2875, -2.2928, -6.0694, -4.2839, -4.0753, -7.1371, -4.9297, -5.5255, -8.0217, 0.9365, -6.5536, -4.9396, 0.6281, 0.6259, 0.604, 0.8253, -0.8136, 1.1665, 0.4195, 0.8192, 1.2122, -6.2908, 0.632, -4.2813, 3.6844, 3.6844, 3.6842, 3.6841, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.4831, 1.1321, 0.8236, 1.0208, 0.8214, -0.6181, 1.362, 1.0147, 0.7995, 1.4078, 0.8275, 1.2166, 1.1823, 1.3486, 0.6151, 0.2091, -4.0857, 0.0585, 1.4369, 1.3023, -0.1124, 1.3786, 1.0349, 1.3409, 1.4372, 1.4278, 1.0092, 3.7402, 3.7401, 3.74, 3.7399, 3.7392, 3.739, 3.7369, 3.7209, 1.3193, 1.3132, 1.3132, 1.3132, 1.3132, 1.3132, 1.3132, 1.3132, 1.3132, 1.3132, 1.3132, 1.3132, 1.3132, 1.3132, 1.3132, 1.3132, 1.3132, 1.3132, 1.3132, 1.3132, 1.3132, 1.3132, -5.06, -5.3333, -2.5897, -5.7159, -5.1755, -5.8508, 0.9622, 0.6537, 0.6576, 0.851, 0.6516, -0.788, 1.1922, 0.4452, -4.2556, -0.1114, 0.8448, 0.6296, 1.2379, 1.267, 1.2698]}, \"token.table\": {\"Topic\": [10, 1, 1, 1, 10, 1, 6, 1, 3, 1, 1, 1, 9, 1, 1, 8, 7, 1, 1, 8, 5, 1, 6, 7, 1, 1, 1, 8, 5, 3, 1, 2, 7, 1, 1, 1, 1, 3, 1, 1, 1, 8, 1, 10, 1, 1, 7, 5, 10, 1, 7, 10, 3, 2, 4, 1, 3, 2, 6, 7, 1, 1, 1, 1, 1, 2, 9, 1, 1, 1, 1, 2, 1, 1, 9, 1, 6, 1, 1, 3, 1, 1, 3, 1, 7, 1, 1, 4, 2, 1, 4, 1, 8, 2, 1, 5, 1, 1, 10, 1, 10, 1, 1, 1, 1, 2, 1, 3, 1, 5, 1, 3, 1, 9, 1, 2, 10, 1, 6, 8, 1, 6], \"Freq\": [0.9981948113331582, 0.6905805743315964, 0.9909395864702124, 0.9994510137666465, 0.9972233364049847, 0.9991908696146262, 0.999562156687621, 0.9998441192237614, 0.9987354160179053, 0.9996059365596638, 0.9997100647326294, 0.999796550881876, 0.9997812183281708, 0.8235971589536487, 0.952124535865798, 0.999826219394909, 0.9998464140502121, 0.998712096297402, 0.4951970449197188, 0.9997539143842518, 0.9996684329204095, 0.6141084643677098, 0.9989147008496783, 0.9991352947501729, 0.5092652789198633, 0.9999723918703747, 0.9899908837760653, 0.9978551478722728, 0.9981833761108606, 0.9998574984902067, 0.9998982293229555, 0.9996709187936951, 0.99988404858255, 0.9998185594997386, 0.9993316949723278, 0.9997748462498588, 0.99908611643195, 0.9997300513386332, 0.9996216925001165, 0.9999332133225409, 0.9984744125112628, 0.9991962461907898, 0.9954811014376287, 0.9986836508464213, 0.6178936339396959, 0.9994032531850694, 0.9985628396810156, 0.9996478827891361, 0.9996775097517164, 0.9997727672731328, 0.999133659517266, 0.9997161934783749, 0.9996487885438009, 0.9999281568175726, 0.9998909381133845, 0.9977932800788416, 0.9997492691529912, 0.999858841579893, 0.9998016675542447, 0.9991896630917328, 0.9997186158142226, 0.5061778960052861, 0.9992141567327846, 0.7080864912066137, 0.7958192748196287, 0.9994794067658553, 0.9997975825486531, 0.9574070104396599, 0.9993784460618869, 0.9995393299985922, 0.9997329088793532, 0.999670566142669, 0.6107315218456627, 0.5090574064853555, 0.9994489879377935, 0.9997116109313929, 0.983089064568578, 0.999804829064022, 0.8231549374394644, 0.999532682259886, 0.6266379419428636, 0.9964814048121224, 0.9998121567581687, 0.9997783932867736, 0.9993014374536306, 0.9996507441873658, 0.8398965339548848, 0.9996037646470685, 0.9994716123966059, 0.9994183107535214, 0.9999471239261845, 0.9979568092445953, 0.9998099677100802, 0.9995508053079905, 0.507278977569571, 0.99988973182748, 0.9997884817552655, 0.013906855664137331, 0.9873867521537505, 0.9996706468080586, 0.9995321914208205, 0.9993035515027283, 0.9997843642925648, 0.9995400429395306, 0.6920392245931164, 0.9990020344349078, 0.9998607464032401, 0.9965608242288788, 0.9996060123083186, 0.999919353325087, 0.9920896789137311, 0.9994477551110369, 0.9998265387720507, 0.9994737851249254, 0.9997422814886769, 0.99778362769329, 0.9993769864861431, 0.9995173736605996, 0.9998702623977623, 0.9953234811095069, 0.9834318698927234, 0.9996211641874264], \"Term\": [\"absolutely\", \"adn\", \"aesthetic\", \"also\", \"ankle\", \"arm\", \"back\", \"beautiful\", \"beautifully\", \"bit\", \"black\", \"bottom\", \"buy\", \"camel\", \"cheste\", \"color\", \"comfortable\", \"comfy\", \"crosswrap\", \"cut\", \"cute\", \"defiantly\", \"definitely\", \"design\", \"differ\", \"dress\", \"elbow\", \"end\", \"extra\", \"fabric\", \"feel\", \"find\", \"fit\", \"flatter\", \"full\", \"get\", \"give\", \"go\", \"good\", \"great\", \"half\", \"high\", \"honey\", \"hope\", \"hunt\", \"jean\", \"knee\", \"large\", \"length\", \"light\", \"line\", \"little\", \"long\", \"look\", \"love\", \"low\", \"make\", \"material\", \"much\", \"never\", \"nice\", \"nightgown\", \"normal\", \"object\", \"obvious\", \"online\", \"order\", \"pain\", \"pant\", \"pattern\", \"perfect\", \"petite\", \"picnic\", \"precious\", \"pretty\", \"purchase\", \"ready\", \"really\", \"regardless\", \"retailer\", \"ribbon\", \"rise\", \"run\", \"sale\", \"say\", \"see\", \"sheath\", \"shirt\", \"short\", \"shoulder\", \"size\", \"skin\", \"skirt\", \"sleeve\", \"slinky\", \"small\", \"soft\", \"somewhere\", \"somewhere\", \"still\", \"store\", \"style\", \"summer\", \"sweater\", \"theory\", \"thin\", \"think\", \"throw\", \"tight\", \"top\", \"travel\", \"true\", \"try\", \"usually\", \"waist\", \"waiste\", \"want\", \"way\", \"wear\", \"week\", \"wise\", \"work\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 3, 10, 4, 6, 7, 9, 1, 2, 8]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el641140250393754304766351456\", ldavis_el641140250393754304766351456_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el641140250393754304766351456\", ldavis_el641140250393754304766351456_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el641140250393754304766351456\", ldavis_el641140250393754304766351456_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgxnFh1uSHHo",
        "outputId": "07ddd1a4-456d-4b2d-b3b2-dfe85e6681f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Perplexity:  -7.194378421192711\n",
            "\n",
            "Coherence Score:  0.6378670459995781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Justifications and questions"
      ],
      "metadata": {
        "id": "xiVzxTh166c7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Topic 1 are about clothes, features of clothes, and behaviors and feelings of customers.  It is the most prevalent topic, much larger than any other topic, which is as expected because the data is about women's clothes reviews.\n",
        "2. From the graph, we can see topic 1 and topic 2 both have no overlapping area with others and they are fairly seperated from the other, which means they are both good topics. But we look at the words in topic 2, most of them seem highly relative to topic 1, like 'look', 'sleeve' and 'short'. Topic 2 is hard to understand what this topic represents.\n",
        "3. Topics expect topic 1 and topic 2 are almost overlapped with each other, clustering at the top-right corner. And it tells us that the number of topics we chose here is too large. We can choose other smaller number of topics to get a better coherence score."
      ],
      "metadata": {
        "id": "LslDw7aN74WY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jBp-XZxOEuHV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}